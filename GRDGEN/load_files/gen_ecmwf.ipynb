{"cells": [{"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["#!/usr/bin/env python"]}, {"cell_type": "markdown", "metadata": {}, "source": ["*********************************************************************<br>\n", "PROGRAM TO GENERATE GRIDS FOR ATMOSPHERIC LOADS FROM ECMWF<br>\n", ":: GRIDS GENERATED MAY BE USED BY LOADDEF (run_cn.py) OR IN GMT<br>\n", "<br>\n", "Copyright (c) 2014-2019: HILARY R. MARTENS, LUIS RIVERA, MARK SIMONS         <br>\n", "<br>\n", "This file is part of LoadDef.<br>\n", "<br>\n", "   LoadDef is free software: you can redistribute it and/or modify<br>\n", "   it under the terms of the GNU General Public License as published by<br>\n", "   the Free Software Foundation, either version 3 of the License, or<br>\n", "   any later version.<br>\n", "<br>\n", "   LoadDef is distributed in the hope that it will be useful,<br>\n", "   but WITHOUT ANY WARRANTY; without even the implied warranty of<br>\n", "   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the<br>\n", "   GNU General Public License for more details.<br>\n", "<br>\n", "   You should have received a copy of the GNU General Public License<br>\n", "   along with LoadDef.  If not, see <https://www.gnu.org/licenses/>.<br>\n", "<br>\n", "*********************************************************************"]}, {"cell_type": "markdown", "metadata": {}, "source": ["MODIFY PYTHON PATH TO INCLUDE 'CONVGF' DIRECTORY"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from __future__ import print_function\n", "import sys\n", "import os\n", "sys.path.append(os.getcwd() + \"/../../\")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["IMPORT PYTHON MODULES"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import numpy as np\n", "import scipy as sc\n", "import datetime\n", "import netCDF4\n", "from GRDGEN.utility import read_ecmwf"]}, {"cell_type": "markdown", "metadata": {}, "source": ["--------------- SPECIFY USER INPUTS --------------------- #"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Atmospheric Surface Pressure Files from ECMWF - MUST HAVE NETCDF4 FOR PYTHON INSTALLED <br>\n", " Specify the directory containing the yearly netcdf files here:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["ecmwf_directory = (\"../../input/Load_Models/ECMWF/Surface_Pressure/\")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Date Range for Temporal-Mean Computation (yyyy, mm, dd); End Day is Included (Files to be Read in)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["start_year_tm = 2016; start_month_tm = 10; start_day_tm = 1\n", "end_year_tm = 2017; end_month_tm = 10; end_day_tm = 1\n", " \n", "# Date Range for Output Files (yyyy, mm, dd); End Day is Included (Files to be Written out)\n", "start_year_out = 2016; start_month_out = 10; start_day_out = 1\n", "end_year_out = 2017; end_month_out = 10; end_day_out = 1"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Remove spatial and temporal averages?"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["rm_spatial_mean = False\n", "rm_temporal_mean = False"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Order in which to remove the temporal (t) and spatial (s) averages (false = t then s; true = s then t)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["flip = False"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Additional Name Tag"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["tmrange = \"%4d%02d%02d-%4d%02d%02d\" % (start_year_tm, start_month_tm, start_day_tm, end_year_tm, end_month_tm, end_day_tm)\n", "add_tag = (tmrange + \"_ECMWF\")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Write Load Information to a netCDF-formatted File? (Default for convolution)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["write_nc = True"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Write Load Information to a Text File? (Alternative for convolution)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["write_txt = False"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Write Load Information to a GMT-formatted File? (Lon, Lat, Amplitude)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["write_gmt = False"]}, {"cell_type": "markdown", "metadata": {}, "source": ["------------------ END USER INPUTS ----------------------- #"]}, {"cell_type": "markdown", "metadata": {}, "source": ["-------------------- BEGIN CODE -------------------------- #"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Check for output of a file"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["if (write_nc == False) and (write_txt == False) and (write_gmt == False):\n", "    print(\":: Error: No output file(s) selected. Options: netCDF, GMT, and/or plain-text.\")\n", "    sys.exit()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Create Folders"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["if not (os.path.isdir(\"../../output/Grid_Files/\")):\n", "    os.makedirs(\"../../output/Grid_Files/\")\n", "if not (os.path.isdir(\"../../output/Grid_Files/GMT/\")):\n", "    os.makedirs(\"../../output/Grid_Files/GMT/\")\n", "if not (os.path.isdir(\"../../output/Grid_Files/GMT/ATML/\")):\n", "    os.makedirs(\"../../output/Grid_Files/GMT/ATML/\")\n", "if not (os.path.isdir(\"../../output/Grid_Files/nc/\")):\n", "    os.makedirs(\"../../output/Grid_Files/nc/\")\n", "if not (os.path.isdir(\"../../output/Grid_Files/nc/ATML/\")):\n", "    os.makedirs(\"../../output/Grid_Files/nc/ATML/\")\n", "if not (os.path.isdir(\"../../output/Grid_Files/text/\")):\n", "    os.makedirs(\"../../output/Grid_Files/text/\")\n", "if not (os.path.isdir(\"../../output/Grid_Files/text/ATML/\")):\n", "    os.makedirs(\"../../output/Grid_Files/text/ATML/\")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Filename Tags"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["if (flip == False): # temporal then spatial\n", "    tag = (\"rmTM1\" + str(rm_temporal_mean) + \"_rmSM2\" + str(rm_spatial_mean) + \"_\" + add_tag + \"_\")\n", "else: # spatial then temporal\n", "    tag = (\"rmSM1\" + str(rm_spatial_mean) + \"_rmTM2\" + str(rm_temporal_mean) + \"_\" + add_tag + \"_\")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Determine Ordinal Dates for Temporal Mean Calculation"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["mydate1 = datetime.datetime(start_year_tm, start_month_tm, start_day_tm,00,00,00) #start_date = datetime.date.toordinal(mydate1)\n", "mydate2 = datetime.datetime(end_year_tm, end_month_tm, end_day_tm,00,00,00) #end_date = datetime.date.toordinal(mydate2)\n", "# Determine Date Range (From Start to End, Increasing by 6 Hours)\n", "delta = datetime.timedelta(hours=6)\n", "curr = mydate1\n", "date_list = []\n", "date_list.append(curr)\n", "while curr < mydate2:\n", "    curr += delta\n", "    date_list.append(curr)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Determine Ordinal Dates for Output"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["mydate1 = datetime.datetime(start_year_out, start_month_out, start_day_out,00,00,00)\n", "mydate2 = datetime.datetime(end_year_out, end_month_out, end_day_out,00,00,00)\n", "# Determine Date Range (From Start to End, Increasing by 6 Hours)\n", "delta = datetime.timedelta(hours=6)\n", "curr = mydate1\n", "date_list_out = []\n", "date_list_out.append(curr)\n", "while curr < mydate2:\n", "    curr += delta\n", "    date_list_out.append(curr)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Determine Number of Dates for Temporal Mean"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["if isinstance(date_list,float) == True:\n", "    numel = 1\n", "else: \n", "    numel = len(date_list)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Determine Number of Dates for Output"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["if isinstance(date_list_out,float) == True:\n", "    numel_out = 1\n", "else:\n", "    numel_out = len(date_list_out)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Check Number of Dates"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["if (numel_out > numel):\n", "    print(':: Warning: Fewer Dates for the Temporal Mean Computation than for the Output Files.')\n", "elif (min(date_list) > min(date_list_out)):\n", "    print(':: Warning: Dates for Output Files are Outside the Range of the Files to be Read in.')\n", "elif (max(date_list) < max(date_list_out)):\n", "    print(':: Warning: Dates for Output Files are Outside the Range of the Files to be Read in.')"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Create Array of String Dates"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["string_dates = []\n", "for qq in range(0,numel):\n", "    mydt = date_list[qq]\n", "    string_dates.append(mydt.strftime('%Y%m%d%H%M%S'))"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Fill Amplitude Array"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["to_mask = np.empty((480*241,len(date_list)))\n", "atml_amp = np.empty((480*241,len(date_list)))\n", "dates_to_delete = []\n", "# SHAPE OF ARRAY\n", "atml_shape = atml_amp.shape\n", "# Loop Through Dates\n", "for ii in range(0,len(date_list)):\n", "    mydt = date_list[ii] \n", "    string_date = mydt.strftime('%Y%m%d%H%M%S') # Convert Date to String in YYYY-mm-dd-HH-MM-SS Format\n", "    print(':: Reading %s' %(string_date))\n", "    string_year = mydt.strftime('%Y') # Convert Date to String in YYYY Format\n", "    string_month = mydt.strftime('%m') # Month\n", "    # Complete Pathname to Current ECMWF File\n", "    loadfile = ecmwf_directory + \"ECMWF-ERA-Interim-\" + string_year + \"-\" + string_month + \".nc\"\n", "    # Read the File \n", "    if (os.path.isfile(loadfile)):\n", "        llat,llon,amp,pha,llat1dseq,llon1dseq,amp2darr,pha2darr = read_ecmwf.main(loadfile,mydt)\n", "        # Combine Amplitude and Phase \n", "        to_mask[:,ii] = np.zeros((atml_shape[0],)) # file exists : do not apply mask\n", "        atml_amp[:,ii] = np.multiply(amp,np.cos(np.radians(pha)))\n", "    else: # File Does Not Exist\n", "        print(':: Warning: File Does Not Exist.')\n", "        # Save date_list index, then continue\n", "        dates_to_delete.append(ii)\n", "        continue"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Delete dates with no data"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["date_list = np.delete(date_list,dates_to_delete)\n", "string_dates = np.delete(string_dates,dates_to_delete)\n", "atml_amp = np.delete(atml_amp,dates_to_delete,axis=1)\n", "to_mask = np.delete(to_mask,dates_to_delete,axis=1)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Order of Removing the Temporal and Spatial Means"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["if (flip == False): # Temporal then Spatial\n", " \n", "    # COMPUTE TEMPORAL MEAN\n", "    if (rm_temporal_mean == True):\n", "        atml_temporal_avg = np.average(atml_amp,axis=1)\n", "        print(':: Computing temporal mean.')\n", "        # Put Averages into Array | Efficient, but Memory Problems for lots of Dates ...\n", "        #atml_temporal_avg_array = np.tile(atml_temporal_avg,(atml_shape[1],1)).T\n", "        # Subtract Temporal Array\n", "        for jj in range(0,len(date_list)): # Loop Takes Longer, but Saves on Memory\n", "            #atml_amp[:,jj] = np.subtract(atml_amp[:,jj], atml_temporal_avg_array[:,jj])\n", "            atml_amp[:,jj] = np.subtract(atml_amp[:,jj], atml_temporal_avg)\n", "    atml_temporal_avg_array = atml_temporal_avg = None\n\n", "    # COMPUTE SPATIAL MEAN\n", "    if (rm_spatial_mean == True):\n", "        # Mask the Array when Computing Spatial Averages\n", "        masked_amp = np.ma.masked_where(to_mask == 1,atml_amp)\n", "        atml_spatial_avg = np.ma.average(masked_amp,axis=0)\n", "        # Convert Back to Numpy Array\n", "        atml_spatial_avg = np.ma.filled(atml_spatial_avg,fill_value=0.)\n", "        print(':: Computing spatial mean.')\n", "        # Put Averages into Array | Efficient, but Memory Problems for lots of Dates ...\n", "        #atml_spatial_avg_array = np.tile(atml_spatial_avg,(atml_shape[0],1))\n", "        # Subtract Spatial Array\n", "        for kk in range(0,len(date_list)): # Loop Takes Longer, but Saves on Memory\n", "            #atml_amp[:,kk] = np.subtract(atml_amp[:,kk], atml_spatial_avg_array[:,kk])\n", "            atml_amp[:,kk] = np.subtract(atml_amp[:,kk], atml_spatial_avg[kk])\n", "    atml_spatial_avg_array = atml_spatial_avg = None"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["else: # Spatial then Temporal\n\n", "    # COMPUTE SPATIAL MEAN\n", "    if (rm_spatial_mean == True):\n", "        # Mask the Array when Computing Spatial Averages\n", "        masked_amp = np.ma.masked_where(to_mask == 1,atml_amp)\n", "        atml_spatial_avg = np.ma.average(masked_amp,axis=0)\n", "        # Convert Back to Numpy Array\n", "        atml_spatial_avg = np.ma.filled(atml_spatial_avg,fill_value=0.)\n", "        print(':: Computing spatial mean.')\n", "        # Put Averages into Array | Efficient, but Memory Problems for lots of Dates ...\n", "        #atml_spatial_avg_array = np.tile(atml_spatial_avg,(atml_shape[0],1))\n", "        # Subtract Spatial Array\n", "        for kk in range(0,len(date_list)): # Loop Takes Longer, but Saves on Memory\n", "            #atml_amp[:,kk] = np.subtract(atml_amp[:,kk], atml_spatial_avg_array[:,kk])\n", "            atml_amp[:,kk] = np.subtract(atml_amp[:,kk], atml_spatial_avg[kk])\n", "    atml_spatial_avg_array = atml_spatial_avg = None\n\n", "    # COMPUTE TEMPORAL MEAN\n", "    if (rm_temporal_mean == True):\n", "        atml_temporal_avg = np.average(atml_amp,axis=1)\n", "        print(':: Computing temporal mean.')\n", "        # Put Averages into Array\n", "        #atml_temporal_avg_array = np.tile(atml_temporal_avg,(atml_shape[1],1)).T\n", "        # Subtract Temporal Array | Efficient, but Memory Problems for lots of Dates ...\n", "        for jj in range(0,len(date_list)): # Loop Takes Longer, but Saves on Memory\n", "            #atml_amp[:,jj] = np.subtract(atml_amp[:,jj], atml_temporal_avg_array[:,jj])\n", "            atml_amp[:,jj] = np.subtract(atml_amp[:,jj], atml_temporal_avg)\n", "    atml_temporal_avg_array = atml_temporal_avg = None"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Convert to Masked Array (Re-set all masked grid points to zero)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["masked_amp = np.ma.masked_where(to_mask == 1,atml_amp)\n", "print(':: Masking the amplitude array.')\n", "for bb in range(0,len(date_list)): # Loop Takes Longer, but Saves on Memory\n", "    atml_amp[:,bb] = np.ma.filled(masked_amp[:,bb],fill_value=0.)\n", "masked_amp = to_mask = None"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Set Phase to Zero (Amplitudes Contain Phase)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["atml_pha = np.zeros((480*241,len(date_list)))"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Loop Through Dates and Write to File"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["for kk in range(0,len(date_list_out)):\n", "    \n", "    # Output ATML Grid to File for Plotting in GMT\n", "    mydt = date_list_out[kk]\n", "    # Convert Date to String in YYYY-mm-dd-HH-MM-SS Format\n", "    string_date = mydt.strftime('%Y%m%d%H%M%S')\n", "    # Find Consistent Dates\n", "    if not string_date in string_dates:\n", "        continue\n", "    # Locate Date in Full Date List\n", "    jj = np.where(string_date == np.asarray(string_dates)); jj = jj[0][0]\n", "    idx = str(jj) # Convert to string to test if a value exists (including zero)\n", "    if not idx:\n", "        print(':: Warning: No Date Match Found for Output Date in Range of Amplitude Array | %s' %(string_date))\n", "        continue\n", "    jj = int(idx) # Convert back to integer to use as index\n", "    # Prepare to Write to File\n", "    print(':: Writing %s' %(string_dates[jj]))\n", "    atml_out = (\"atml_\" + tag + string_date + \".txt\")\n", "    atml_out_nc = (\"atml_\" + tag + string_date + \".nc\")\n", "    atml_file = (\"../../output/Grid_Files/GMT/ATML/height-anomaly_\" + atml_out)\n", "    atml_file_pressure = (\"../../output/Grid_Files/GMT/ATML/pressure_\" + atml_out)\n", "    atml_file_nc = (\"../../output/Grid_Files/nc/ATML/convgf_\" + atml_out_nc)\n", "    atml_file_text = (\"../../output/Grid_Files/text/ATML/convgf_\" + atml_out)\n", "    # Prepare Data\n", "    all_atml_data = np.column_stack((llon,llat,atml_amp[:,jj]))\n", "    all_atml_data_pressure = np.column_stack((llon,llat,atml_amp[:,jj]*9.81))\n", "    all_atml_data_convgf = np.column_stack((llat,llon,atml_amp[:,jj],atml_pha[:,jj]))\n", "    # Write Files\n", "    if (write_nc == True):\n", "        print(\":: Writing netCDF-formatted file.\")\n", "        # Open new NetCDF file in \"write\" mode\n", "        dataset = netCDF4.Dataset(atml_file_nc,'w',format='NETCDF4_CLASSIC')\n", "        # Define dimensions for variables\n", "        num_pts = len(llat)\n", "        latitude = dataset.createDimension('latitude',num_pts)\n", "        longitude = dataset.createDimension('longitude',num_pts)\n", "        amplitude = dataset.createDimension('amplitude',num_pts)\n", "        phase = dataset.createDimension('phase',num_pts)\n", "        # Create variables\n", "        latitudes = dataset.createVariable('latitude',np.float,('latitude',))\n", "        longitudes = dataset.createVariable('longitude',np.float,('longitude',))\n", "        amplitudes = dataset.createVariable('amplitude',np.float,('amplitude',))\n", "        phases = dataset.createVariable('phase',np.float,('phase',))\n", "        # Add units\n", "        latitudes.units = 'degree_north'\n", "        longitudes.units = 'degree_east'\n", "        amplitudes.units = 'm'\n", "        phases.units = 'degree'\n", "        # Assign data\n", "        latitudes[:] = llat\n", "        longitudes[:] = llon\n", "        amplitudes[:] = atml_amp[:,jj]\n", "        phases[:] = atml_pha[:,jj]\n", "        # Write Data to File\n", "        dataset.close()\n", "    if (write_gmt == True):\n", "        print(\":: Writing to GMT-convenient text file.\")\n", "        np.savetxt(atml_file, all_atml_data, fmt='%f %f %f')\n", "        np.savetxt(atml_file_pressure, all_atml_data_pressure, fmt='%f %f %f')\n", "    if (write_txt == True):\n", "        print(\":: Writing to plain-text file.\")\n", "        np.savetxt(atml_file_text, all_atml_data_convgf, fmt='%f %f %f %f')"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["if (write_gmt == True):\n", "    print(\":: Writing to GMT-convenient text file.\")\n", "    # Compute Standard Deviation for Each Amplitude Pixel\n", "    atml_std = np.std(atml_amp,axis=1)\n", "    # Export Standard Deviation to File\n", "    atml_out = \"atml_std_\" + string_dates[0] + \"_\" + string_dates[-1] + \".txt\"\n", "    atml_file = (\"../../output/Grid_Files/GMT/ATML/height-anomaly_\" + atml_out)\n", "    atml_file_pressure = (\"../../output/Grid_Files/GMT/ATML/pressure_\" + atml_out)\n", "    # Prepare Data\n", "    all_atml_data = np.column_stack((llon,llat,atml_std))\n", "    all_atml_data_pressure = np.column_stack((llon,llat,atml_std*9.81))\n", "    # Write Data to File\n", "    np.savetxt(atml_file, all_atml_data, fmt='%f %f %f')\n", "    np.savetxt(atml_file_pressure, all_atml_data_pressure, fmt='%f %f %f')\n\n", "    # Compute Maximum for Each Amplitude Pixel\n", "    atml_abs = np.absolute(atml_amp)\n", "    atml_max = np.amax(atml_abs,axis=1)\n", "    # Export Standard Deviation to File\n", "    atml_out = \"atml_max_\" + string_dates[0] + \"_\" + string_dates[-1] + \".txt\"\n", "    atml_file = (\"../../output/Grid_Files/GMT/ATML/height-anomaly_\" + atml_out)\n", "    atml_file_pressure = (\"../../output/Grid_Files/GMT/ATML/pressure_\" + atml_out)\n", "    # Prepare Data\n", "    all_atml_data = np.column_stack((llon,llat,atml_max))\n", "    all_atml_data_pressure = np.column_stack((llon,llat,atml_max*9.81))\n", "    # Write Data to File\n", "    np.savetxt(atml_file, all_atml_data, fmt='%f %f %f')\n", "    np.savetxt(atml_file_pressure, all_atml_data_pressure, fmt='%f %f %f')"]}, {"cell_type": "markdown", "metadata": {}, "source": ["--------------------- END CODE --------------------------- #"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.6.4"}}, "nbformat": 4, "nbformat_minor": 2}