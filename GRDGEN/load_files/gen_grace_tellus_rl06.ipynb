{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*********************************************************************<br>\n",
    "PROGRAM TO GENERATE GRIDS FOR LOADS FROM GRACE<br>\n",
    ":: GRIDS GENERATED HERE MAY BE USED BY LOADDEF (run_cn_[].py) OR IN GMT<br>\n",
    "<br>\n",
    "Copyright (c) 2014-2023: HILARY R. MARTENS, LUIS RIVERA, MARK SIMONS         <br>\n",
    "<br>\n",
    "This file is part of LoadDef.<br>\n",
    "<br>\n",
    "   LoadDef is free software: you can redistribute it and/or modify<br>\n",
    "   it under the terms of the GNU General Public License as published by<br>\n",
    "   the Free Software Foundation, either version 3 of the License, or<br>\n",
    "   any later version.<br>\n",
    "<br>\n",
    "   LoadDef is distributed in the hope that it will be useful,<br>\n",
    "   but WITHOUT ANY WARRANTY; without even the implied warranty of<br>\n",
    "   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the<br>\n",
    "   GNU General Public License for more details.<br>\n",
    "<br>\n",
    "   You should have received a copy of the GNU General Public License<br>\n",
    "   along with LoadDef.  If not, see <https://www.gnu.org/licenses/>.<br>\n",
    "<br>\n",
    "*********************************************************************"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MODIFY PYTHON PATH TO INCLUDE 'CONVGF' DIRECTORY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(os.getcwd() + \"/../../\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IMPORT PYTHON MODULES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as sc\n",
    "import datetime\n",
    "import netCDF4 \n",
    "from GRDGEN.utility import read_grace_tellus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------- SPECIFY USER INPUTS --------------------- #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Atmospheric Surface Pressure Files from GRACE - MUST HAVE NETCDF4 FOR PYTHON INSTALLED <br>\n",
    " Specify the directory containing the yearly netcdf files here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "grace_directory = (\"../../input/Load_Models/GRACE-Tellus-RL06/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Date Range for Temporal-Mean Computation (yyyy, mm, dd); End Day is Included (Files to be Read in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start_year_tm = 2019; start_month_tm = 10; start_day_tm = 1\n",
    "# end_year_tm = 2021; end_month_tm = 10; end_day_tm = 1\n",
    "start_year_tm = 2016; start_month_tm = 1; start_day_tm = 1\n",
    "end_year_tm = 2022; end_month_tm = 12; end_day_tm = 31\n",
    "\n",
    "  \n",
    "# Date Range for Output Files (yyyy, mm, dd); End Day is Included (Files to be Written out)\n",
    "#start_year_out = 2019; start_month_out = 10; start_day_out = 1\n",
    "#end_year_out = 2021; end_month_out = 10; end_day_out = 1\n",
    "\n",
    "start_year_out = 2016; start_month_out = 1; start_day_out = 1\n",
    "end_year_out = 2022; end_month_out = 12; end_day_out = 31\n",
    "  \n",
    "# Remove spatial and temporal averages?\n",
    "rm_spatial_mean = False\n",
    "rm_temporal_mean = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Order in which to remove the temporal (t) and spatial (s) averages (false = t then s; true = s then t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "flip = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Additional Name Tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmrange = \"%4d%02d%02d-%4d%02d%02d\" % (start_year_tm, start_month_tm, start_day_tm, end_year_tm, end_month_tm, end_day_tm)\n",
    "add_tag = (tmrange + \"_GRACE_Tellus_RL06\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Complete Pathname to Current GRACE File"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loadfile1 = grace_directory + \"GRCTellus.JPL.200204_202205.GLO.RL06M.MSCNv02CRI.nc\"\n",
    "loadfile1 = grace_directory + \"GRCTellus.JPL.200204_202311.GLO.RL06.1M.MSCNv03.nc\" # newest file to March/1/2024\n",
    "tag1 = \"JPL\"\n",
    " \n",
    "# Second solution\n",
    "loadfile2 = None \n",
    "tag2 = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Third solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "loadfile3 = None\n",
    "tag3 = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scaling factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaling = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Average solutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "avgsol = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply GRACE scaling factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "appscl = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Solution tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (avgsol == True):\n",
    "    soltag = (tag1 + \"-\" + tag2 + \"-\" + tag3)\n",
    "else:\n",
    "    soltag = (tag1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write Load Information to a netCDF-formatted File? (Default for convolution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_nc = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write Load Information to a Text File? (Alternative for convolution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_txt = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write Load Information to a GMT-formatted File?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_gmt = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------ END USER INPUTS ----------------------- #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------- BEGIN CODE -------------------------- #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check for output of a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (write_nc == False) and (write_txt == False) and (write_gmt == False):\n",
    "    print(\":: Error: No output file(s) selected. Options: netCDF, GMT, and/or plain-text.\")\n",
    "    sys.exit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not (os.path.isdir(\"../../output/Grid_Files/\")):\n",
    "    os.makedirs(\"../../output/Grid_Files/\")\n",
    "if not (os.path.isdir(\"../../output/Grid_Files/GMT/\")):\n",
    "    os.makedirs(\"../../output/Grid_Files/GMT/\")\n",
    "if not (os.path.isdir(\"../../output/Grid_Files/GMT/GRACE/\")):\n",
    "    os.makedirs(\"../../output/Grid_Files/GMT/GRACE/\")\n",
    "if not (os.path.isdir(\"../../output/Grid_Files/nc/\")):\n",
    "    os.makedirs(\"../../output/Grid_Files/nc/\")\n",
    "if not (os.path.isdir(\"../../output/Grid_Files/nc/GRACE/\")):\n",
    "    os.makedirs(\"../../output/Grid_Files/nc/GRACE/\")\n",
    "if not (os.path.isdir(\"../../output/Grid_Files/text/\")):\n",
    "    os.makedirs(\"../../output/Grid_Files/text/\")\n",
    "if not (os.path.isdir(\"../../output/Grid_Files/text/GRACE/\")):\n",
    "    os.makedirs(\"../../output/Grid_Files/text/GRACE/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filename Tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (flip == False): # temporal then spatial\n",
    "    tag = (\"rmTM1\" + str(rm_temporal_mean) + \"_rmSM2\" + str(rm_spatial_mean) + \"_\" + add_tag + \"_\" + soltag + \"_Scaling\" + str(appscl) + \"_\")\n",
    "else: # spatial then temporal\n",
    "    tag = (\"rmSM1\" + str(rm_spatial_mean) + \"_rmTM2\" + str(rm_temporal_mean) + \"_\" + add_tag + \"_\" + soltag + \"_Scaling\" + str(appscl) + \"_\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Determine Ordinal Dates for Temporal Mean Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "mydate1 = datetime.datetime(start_year_tm, start_month_tm, start_day_tm, 0, 0, 0) #start_date = datetime.date.toordinal(mydate1)\n",
    "mydate2 = datetime.datetime(end_year_tm, end_month_tm, end_day_tm, 0, 0, 0) #end_date = datetime.date.toordinal(mydate2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Determine Date Range (From Start to End, Increasing by 1 day; sometimes GRACE has two models per month)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "curr = mydate1\n",
    "date_list = []\n",
    "date_list.append(curr)\n",
    "count = 0\n",
    "while curr < mydate2:\n",
    "    curr += datetime.timedelta(days=1)\n",
    "    date_list.append(curr)\n",
    "# Determine Date Range (From Start to End, Increasing by 30 days)\n",
    "#    count = count+1\n",
    "#    if ((start_month_tm + count) == 13):\n",
    "#        start_year_tm += 1\n",
    "#        start_month_tm = 1\n",
    "#        count = 0\n",
    "#    curr = datetime.datetime(start_year_tm, (start_month_tm + count), 1,0,0,0)\n",
    "#    date_list.append(curr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Determine Ordinal Dates for Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "mydate1 = datetime.datetime(start_year_out, start_month_out, start_day_out, 0, 0, 0)\n",
    "mydate2 = datetime.datetime(end_year_out, end_month_out, end_day_out, 0, 0, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Determine Date Range (From Start to End, Increasing by 1 day; sometimes GRACE has two models per month)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "curr = mydate1\n",
    "date_list_out = []\n",
    "date_list_out.append(curr)\n",
    "count = 0\n",
    "while curr < mydate2:\n",
    "    curr += datetime.timedelta(days=1)\n",
    "    date_list_out.append(curr)\n",
    "# Determine Date Range (From Start to End, Increasing by 30 days)\n",
    "#    count = count+1\n",
    "#    if ((start_month_out + count) == 13):\n",
    "#        start_year_out += 1\n",
    "#        start_month_out = 1\n",
    "#        count = 0\n",
    "#    curr = datetime.datetime(start_year_out, (start_month_out + count), 1,0,0,0)\n",
    "#    date_list_out.append(curr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Determine Number of Dates for Temporal Mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "if isinstance(date_list,float) == True:\n",
    "    numel = 1\n",
    "else: \n",
    "    numel = len(date_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Determine Number of Dates for Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "if isinstance(date_list_out,float) == True:\n",
    "    numel_out = 1\n",
    "else:\n",
    "    numel_out = len(date_list_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check Number of Dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (numel_out > numel):\n",
    "    print(':: Warning: Fewer Dates for the Temporal Mean Computation than for the Output Files.')\n",
    "elif (min(date_list) > min(date_list_out)):\n",
    "    print(':: Warning: Dates for Output Files are Outside the Range of the Files to be Read in.')\n",
    "elif (max(date_list) < max(date_list_out)):\n",
    "    print(':: Warning: Dates for Output Files are Outside the Range of the Files to be Read in.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Array of String Dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "string_dates = []\n",
    "for qq in range(0,numel):\n",
    "    mydt = date_list[qq]\n",
    "    string_dates.append(mydt.strftime('%Y%m%d%H%M%S'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fill Amplitude Array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: Reading 20160101000000\n",
      ":: Reading 20160102000000\n",
      ":: Reading 20160103000000\n",
      ":: Reading 20160104000000\n",
      ":: Reading 20160105000000\n",
      ":: Reading 20160106000000\n",
      ":: Reading 20160107000000\n",
      ":: Reading 20160108000000\n",
      ":: Reading 20160109000000\n",
      ":: Reading 20160110000000\n",
      ":: Reading 20160111000000\n",
      ":: Reading 20160112000000\n",
      ":: Reading 20160113000000\n",
      ":: Reading 20160114000000\n",
      ":: Reading 20160115000000\n",
      ":: Reading 20160116000000\n",
      "(259200, 2557)\n",
      ":: Reading 20160117000000\n",
      ":: Reading 20160118000000\n",
      ":: Reading 20160119000000\n",
      ":: Reading 20160120000000\n",
      ":: Reading 20160121000000\n",
      ":: Reading 20160122000000\n",
      ":: Reading 20160123000000\n",
      ":: Reading 20160124000000\n",
      ":: Reading 20160125000000\n",
      ":: Reading 20160126000000\n",
      ":: Reading 20160127000000\n",
      ":: Reading 20160128000000\n",
      ":: Reading 20160129000000\n",
      ":: Reading 20160130000000\n",
      ":: Reading 20160131000000\n",
      ":: Reading 20160201000000\n",
      ":: Reading 20160202000000\n",
      ":: Reading 20160203000000\n",
      ":: Reading 20160204000000\n",
      ":: Reading 20160205000000\n",
      ":: Reading 20160206000000\n",
      ":: Reading 20160207000000\n",
      ":: Reading 20160208000000\n",
      ":: Reading 20160209000000\n",
      ":: Reading 20160210000000\n",
      ":: Reading 20160211000000\n",
      ":: Reading 20160212000000\n",
      ":: Reading 20160213000000\n",
      ":: Reading 20160214000000\n",
      "(259200, 2557)\n",
      ":: Reading 20160215000000\n",
      ":: Reading 20160216000000\n",
      ":: Reading 20160217000000\n",
      ":: Reading 20160218000000\n",
      ":: Reading 20160219000000\n",
      ":: Reading 20160220000000\n",
      ":: Reading 20160221000000\n",
      ":: Reading 20160222000000\n",
      ":: Reading 20160223000000\n",
      ":: Reading 20160224000000\n",
      ":: Reading 20160225000000\n",
      ":: Reading 20160226000000\n",
      ":: Reading 20160227000000\n",
      ":: Reading 20160228000000\n",
      ":: Reading 20160229000000\n",
      ":: Reading 20160301000000\n",
      ":: Reading 20160302000000\n",
      ":: Reading 20160303000000\n",
      ":: Reading 20160304000000\n",
      ":: Reading 20160305000000\n",
      ":: Reading 20160306000000\n",
      ":: Reading 20160307000000\n",
      ":: Reading 20160308000000\n",
      ":: Reading 20160309000000\n",
      ":: Reading 20160310000000\n",
      ":: Reading 20160311000000\n",
      ":: Reading 20160312000000\n",
      ":: Reading 20160313000000\n",
      ":: Reading 20160314000000\n",
      ":: Reading 20160315000000\n",
      ":: Reading 20160316000000\n",
      "(259200, 2557)\n",
      ":: Reading 20160317000000\n",
      ":: Reading 20160318000000\n",
      ":: Reading 20160319000000\n",
      ":: Reading 20160320000000\n",
      ":: Reading 20160321000000\n",
      ":: Reading 20160322000000\n",
      ":: Reading 20160323000000\n",
      ":: Reading 20160324000000\n",
      ":: Reading 20160325000000\n",
      ":: Reading 20160326000000\n",
      ":: Reading 20160327000000\n",
      ":: Reading 20160328000000\n",
      ":: Reading 20160329000000\n",
      ":: Reading 20160330000000\n",
      ":: Reading 20160331000000\n",
      ":: Reading 20160401000000\n",
      ":: Reading 20160402000000\n",
      ":: Reading 20160403000000\n",
      ":: Reading 20160404000000\n",
      ":: Reading 20160405000000\n",
      ":: Reading 20160406000000\n",
      ":: Reading 20160407000000\n",
      ":: Reading 20160408000000\n",
      ":: Reading 20160409000000\n",
      ":: Reading 20160410000000\n",
      ":: Reading 20160411000000\n",
      ":: Reading 20160412000000\n",
      ":: Reading 20160413000000\n",
      ":: Reading 20160414000000\n",
      ":: Reading 20160415000000\n",
      ":: Reading 20160416000000\n",
      ":: Reading 20160417000000\n",
      ":: Reading 20160418000000\n",
      ":: Reading 20160419000000\n",
      ":: Reading 20160420000000\n",
      ":: Reading 20160421000000\n",
      ":: Reading 20160422000000\n",
      ":: Reading 20160423000000\n",
      ":: Reading 20160424000000\n",
      ":: Reading 20160425000000\n",
      ":: Reading 20160426000000\n",
      ":: Reading 20160427000000\n",
      ":: Reading 20160428000000\n",
      ":: Reading 20160429000000\n",
      ":: Reading 20160430000000\n",
      ":: Reading 20160501000000\n",
      ":: Reading 20160502000000\n",
      ":: Reading 20160503000000\n",
      ":: Reading 20160504000000\n",
      ":: Reading 20160505000000\n",
      ":: Reading 20160506000000\n",
      ":: Reading 20160507000000\n",
      ":: Reading 20160508000000\n",
      ":: Reading 20160509000000\n",
      ":: Reading 20160510000000\n",
      ":: Reading 20160511000000\n",
      ":: Reading 20160512000000\n",
      ":: Reading 20160513000000\n",
      ":: Reading 20160514000000\n",
      ":: Reading 20160515000000\n",
      ":: Reading 20160516000000\n",
      ":: Reading 20160517000000\n",
      ":: Reading 20160518000000\n",
      ":: Reading 20160519000000\n",
      ":: Reading 20160520000000\n",
      "(259200, 2557)\n",
      ":: Reading 20160521000000\n",
      ":: Reading 20160522000000\n",
      ":: Reading 20160523000000\n",
      ":: Reading 20160524000000\n",
      ":: Reading 20160525000000\n",
      ":: Reading 20160526000000\n",
      ":: Reading 20160527000000\n",
      ":: Reading 20160528000000\n",
      ":: Reading 20160529000000\n",
      ":: Reading 20160530000000\n",
      ":: Reading 20160531000000\n",
      ":: Reading 20160601000000\n",
      ":: Reading 20160602000000\n",
      ":: Reading 20160603000000\n",
      ":: Reading 20160604000000\n",
      ":: Reading 20160605000000\n",
      ":: Reading 20160606000000\n",
      ":: Reading 20160607000000\n",
      ":: Reading 20160608000000\n",
      ":: Reading 20160609000000\n",
      ":: Reading 20160610000000\n",
      ":: Reading 20160611000000\n",
      ":: Reading 20160612000000\n",
      ":: Reading 20160613000000\n",
      ":: Reading 20160614000000\n",
      ":: Reading 20160615000000\n",
      ":: Reading 20160616000000\n",
      "(259200, 2557)\n",
      ":: Reading 20160617000000\n",
      ":: Reading 20160618000000\n",
      ":: Reading 20160619000000\n",
      ":: Reading 20160620000000\n",
      ":: Reading 20160621000000\n",
      ":: Reading 20160622000000\n",
      ":: Reading 20160623000000\n",
      ":: Reading 20160624000000\n",
      ":: Reading 20160625000000\n",
      ":: Reading 20160626000000\n",
      ":: Reading 20160627000000\n",
      ":: Reading 20160628000000\n",
      ":: Reading 20160629000000\n",
      ":: Reading 20160630000000\n",
      ":: Reading 20160701000000\n",
      ":: Reading 20160702000000\n",
      ":: Reading 20160703000000\n",
      ":: Reading 20160704000000\n",
      ":: Reading 20160705000000\n",
      ":: Reading 20160706000000\n",
      ":: Reading 20160707000000\n",
      ":: Reading 20160708000000\n",
      ":: Reading 20160709000000\n",
      ":: Reading 20160710000000\n",
      ":: Reading 20160711000000\n",
      ":: Reading 20160712000000\n",
      ":: Reading 20160713000000\n",
      ":: Reading 20160714000000\n",
      ":: Reading 20160715000000\n",
      "(259200, 2557)\n",
      ":: Reading 20160716000000\n",
      ":: Reading 20160717000000\n",
      ":: Reading 20160718000000\n",
      ":: Reading 20160719000000\n",
      ":: Reading 20160720000000\n",
      ":: Reading 20160721000000\n",
      ":: Reading 20160722000000\n",
      ":: Reading 20160723000000\n",
      ":: Reading 20160724000000\n",
      ":: Reading 20160725000000\n",
      ":: Reading 20160726000000\n",
      ":: Reading 20160727000000\n",
      ":: Reading 20160728000000\n",
      ":: Reading 20160729000000\n",
      ":: Reading 20160730000000\n",
      ":: Reading 20160731000000\n",
      ":: Reading 20160801000000\n",
      ":: Reading 20160802000000\n",
      ":: Reading 20160803000000\n",
      ":: Reading 20160804000000\n",
      ":: Reading 20160805000000\n",
      ":: Reading 20160806000000\n",
      ":: Reading 20160807000000\n",
      ":: Reading 20160808000000\n",
      ":: Reading 20160809000000\n",
      ":: Reading 20160810000000\n",
      ":: Reading 20160811000000\n",
      ":: Reading 20160812000000\n",
      ":: Reading 20160813000000\n",
      ":: Reading 20160814000000\n",
      ":: Reading 20160815000000\n",
      ":: Reading 20160816000000\n",
      ":: Reading 20160817000000\n",
      ":: Reading 20160818000000\n",
      ":: Reading 20160819000000\n",
      ":: Reading 20160820000000\n",
      ":: Reading 20160821000000\n",
      "(259200, 2557)\n",
      ":: Reading 20160822000000\n",
      ":: Reading 20160823000000\n",
      ":: Reading 20160824000000\n",
      ":: Reading 20160825000000\n",
      ":: Reading 20160826000000\n",
      ":: Reading 20160827000000\n",
      ":: Reading 20160828000000\n",
      ":: Reading 20160829000000\n",
      ":: Reading 20160830000000\n",
      ":: Reading 20160831000000\n",
      ":: Reading 20160901000000\n",
      ":: Reading 20160902000000\n",
      ":: Reading 20160903000000\n",
      ":: Reading 20160904000000\n",
      ":: Reading 20160905000000\n",
      ":: Reading 20160906000000\n",
      ":: Reading 20160907000000\n",
      ":: Reading 20160908000000\n",
      ":: Reading 20160909000000\n",
      ":: Reading 20160910000000\n",
      ":: Reading 20160911000000\n",
      ":: Reading 20160912000000\n",
      ":: Reading 20160913000000\n",
      ":: Reading 20160914000000\n",
      ":: Reading 20160915000000\n",
      ":: Reading 20160916000000\n",
      ":: Reading 20160917000000\n",
      ":: Reading 20160918000000\n",
      ":: Reading 20160919000000\n",
      ":: Reading 20160920000000\n",
      ":: Reading 20160921000000\n",
      ":: Reading 20160922000000\n",
      ":: Reading 20160923000000\n",
      ":: Reading 20160924000000\n",
      ":: Reading 20160925000000\n",
      ":: Reading 20160926000000\n",
      ":: Reading 20160927000000\n",
      ":: Reading 20160928000000\n",
      ":: Reading 20160929000000\n",
      ":: Reading 20160930000000\n",
      ":: Reading 20161001000000\n",
      ":: Reading 20161002000000\n",
      ":: Reading 20161003000000\n",
      ":: Reading 20161004000000\n",
      ":: Reading 20161005000000\n",
      ":: Reading 20161006000000\n",
      ":: Reading 20161007000000\n",
      ":: Reading 20161008000000\n",
      ":: Reading 20161009000000\n",
      ":: Reading 20161010000000\n",
      ":: Reading 20161011000000\n",
      ":: Reading 20161012000000\n",
      ":: Reading 20161013000000\n",
      ":: Reading 20161014000000\n",
      ":: Reading 20161015000000\n",
      ":: Reading 20161016000000\n",
      ":: Reading 20161017000000\n",
      ":: Reading 20161018000000\n",
      ":: Reading 20161019000000\n",
      ":: Reading 20161020000000\n",
      ":: Reading 20161021000000\n",
      ":: Reading 20161022000000\n",
      ":: Reading 20161023000000\n",
      ":: Reading 20161024000000\n",
      ":: Reading 20161025000000\n",
      ":: Reading 20161026000000\n",
      ":: Reading 20161027000000\n",
      ":: Reading 20161028000000\n",
      ":: Reading 20161029000000\n",
      ":: Reading 20161030000000\n",
      ":: Reading 20161031000000\n",
      ":: Reading 20161101000000\n",
      ":: Reading 20161102000000\n",
      ":: Reading 20161103000000\n",
      ":: Reading 20161104000000\n",
      ":: Reading 20161105000000\n",
      ":: Reading 20161106000000\n",
      ":: Reading 20161107000000\n",
      ":: Reading 20161108000000\n",
      ":: Reading 20161109000000\n",
      ":: Reading 20161110000000\n",
      ":: Reading 20161111000000\n",
      ":: Reading 20161112000000\n",
      ":: Reading 20161113000000\n",
      ":: Reading 20161114000000\n",
      ":: Reading 20161115000000\n",
      ":: Reading 20161116000000\n",
      ":: Reading 20161117000000\n",
      ":: Reading 20161118000000\n",
      ":: Reading 20161119000000\n",
      ":: Reading 20161120000000\n",
      ":: Reading 20161121000000\n",
      ":: Reading 20161122000000\n",
      ":: Reading 20161123000000\n",
      ":: Reading 20161124000000\n",
      ":: Reading 20161125000000\n",
      ":: Reading 20161126000000\n",
      ":: Reading 20161127000000\n",
      "(259200, 2557)\n",
      ":: Reading 20161128000000\n",
      ":: Reading 20161129000000\n",
      ":: Reading 20161130000000\n",
      ":: Reading 20161201000000\n",
      ":: Reading 20161202000000\n",
      ":: Reading 20161203000000\n",
      ":: Reading 20161204000000\n",
      ":: Reading 20161205000000\n",
      ":: Reading 20161206000000\n",
      ":: Reading 20161207000000\n",
      ":: Reading 20161208000000\n",
      ":: Reading 20161209000000\n",
      ":: Reading 20161210000000\n",
      ":: Reading 20161211000000\n",
      ":: Reading 20161212000000\n",
      ":: Reading 20161213000000\n",
      ":: Reading 20161214000000\n",
      ":: Reading 20161215000000\n",
      ":: Reading 20161216000000\n",
      ":: Reading 20161217000000\n",
      ":: Reading 20161218000000\n",
      ":: Reading 20161219000000\n",
      ":: Reading 20161220000000\n",
      ":: Reading 20161221000000\n",
      ":: Reading 20161222000000\n",
      ":: Reading 20161223000000\n",
      ":: Reading 20161224000000\n",
      "(259200, 2557)\n",
      ":: Reading 20161225000000\n",
      ":: Reading 20161226000000\n",
      ":: Reading 20161227000000\n",
      ":: Reading 20161228000000\n",
      ":: Reading 20161229000000\n",
      ":: Reading 20161230000000\n",
      ":: Reading 20161231000000\n",
      ":: Reading 20170101000000\n",
      ":: Reading 20170102000000\n",
      ":: Reading 20170103000000\n",
      ":: Reading 20170104000000\n",
      ":: Reading 20170105000000\n",
      ":: Reading 20170106000000\n",
      ":: Reading 20170107000000\n",
      ":: Reading 20170108000000\n",
      ":: Reading 20170109000000\n",
      ":: Reading 20170110000000\n",
      ":: Reading 20170111000000\n",
      ":: Reading 20170112000000\n",
      ":: Reading 20170113000000\n",
      ":: Reading 20170114000000\n",
      ":: Reading 20170115000000\n",
      ":: Reading 20170116000000\n",
      ":: Reading 20170117000000\n",
      ":: Reading 20170118000000\n",
      ":: Reading 20170119000000\n",
      ":: Reading 20170120000000\n",
      ":: Reading 20170121000000\n",
      "(259200, 2557)\n",
      ":: Reading 20170122000000\n"
     ]
    }
   ],
   "source": [
    "to_mask = np.empty((360*720,len(date_list)))\n",
    "grace_amp = np.empty((360*720,len(date_list)))\n",
    "dates_to_delete = []\n",
    "# SHAPE OF ARRAY\n",
    "grace_shape = grace_amp.shape\n",
    "# Loop Through Dates\n",
    "for ii in range(0,len(date_list)):\n",
    "    mydt = date_list[ii] \n",
    "    string_date = mydt.strftime('%Y%m%d%H%M%S') # Convert Date to String in YYYY-mm-dd-HH-MM-SS Format\n",
    "    print(':: Reading %s' %(string_date))\n",
    "    string_year = mydt.strftime('%Y') # Convert Date to String in YYYY Format\n",
    "    \n",
    "    # Read the File \n",
    "    if (os.path.isfile(loadfile1)):\n",
    "        llat,llon,amp,pha,llat1dseq,llon1dseq,amp2darr,pha2darr = read_grace_tellus.main(loadfile1,mydt,ldfl2=loadfile2,ldfl3=loadfile3,scl=scaling,avsolns=avgsol,appscaling=appscl)\n",
    "        if llat is None:\n",
    "            #print(':: Checking next date for a data entry...')\n",
    "            # Save date_list index, then continue\n",
    "            dates_to_delete.append(ii)\n",
    "            continue\n",
    "            #to_mask[:,ii] = np.ones((grace_shape[0],)) # set mask to true\n",
    "            #grace_amp[:,ii] = np.zeros((grace_shape[0],))\n",
    "        # Combine Amplitude and Phase \n",
    "        else:\n",
    "            to_mask[:,ii] = np.zeros((grace_shape[0],))\n",
    "            grace_amp[:,ii] = np.multiply(amp,np.cos(np.radians(pha)))\n",
    "            lat_array = llat.copy()\n",
    "            lon_array = llon.copy()\n",
    "            print(grace_amp.shape)\n",
    "    else: # File Does Not Exist\n",
    "        print(':: Load file could not be found.')\n",
    "        #to_mask[:,ii] = np.ones((grace_shape[0],)) # set mask to true\n",
    "        #grace_amp[:,ii] = np.zeros((grace_shape[0],))\n",
    "\n",
    "# Added by C. Hurtado-Pulido\n",
    "# Possible error: Unable to allocate X GiB for an array with shape (xxx, XXX) and data type float64\n",
    "# Solution: Even if the computer does have space, in Ubuntu we need permission to allocate more space.\n",
    "# 1. Close all but the terminal and this window. \n",
    "# 2. In the terminal write echo 1 | sudo tee /proc/sys/vm/overcommit_memory\n",
    "# Explaination here https://www.baeldung.com/linux/overcommit-modes and here https://stackoverflow.com/questions/57507832/unable-to-allocate-array-with-shape-and-data-type\n",
    "# 3. Return back to 0-mode echo 0 | sudo tee /proc/sys/vm/overcommit_memory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Delete dates with no data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_list = np.delete(date_list,dates_to_delete)\n",
    "string_dates = np.delete(string_dates,dates_to_delete)\n",
    "grace_amp = np.delete(grace_amp,dates_to_delete,axis=1)\n",
    "to_mask = np.delete(to_mask,dates_to_delete,axis=1)\n",
    "llat = lat_array.copy(); llon = lon_array.copy()\n",
    "print(grace_amp.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Order of Removing the Temporal and Spatial Means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (flip == False): # Temporal then Spatial\n",
    "    # COMPUTE TEMPORAL MEAN\n",
    "    if (rm_temporal_mean == True):\n",
    "        grace_temporal_avg = np.average(grace_amp,axis=1)\n",
    "        print(('Maximum amplitude (meters): ', np.max(grace_amp)))\n",
    "        print(':: Computing temporal mean.')\n",
    "        # Put Averages into Array | Efficient, but Memory Problems for lots of Dates ...\n",
    "        #grace_temporal_avg_array = np.tile(grace_temporal_avg,(grace_shape[1],1)).T\n",
    "        # Subtract Temporal Array\n",
    "        for jj in range(0,len(date_list)): # Loop Takes Longer, but Saves on Memory\n",
    "            #grace_amp[:,jj] = np.subtract(grace_amp[:,jj], grace_temporal_avg_array[:,jj])\n",
    "            #print(max(grace_amp[:,jj]))            \n",
    "            grace_amp[:,jj] = np.subtract(grace_amp[:,jj], grace_temporal_avg)\n",
    "            #print(max(grace_amp[:,jj])) \n",
    "        #print(grace_temporal_avg)\n",
    "        #print(grace_amp)\n",
    "    grace_temporal_avg_array = grace_temporal_avg = None\n",
    "    # COMPUTE SPATIAL MEAN\n",
    "    if (rm_spatial_mean == True):\n",
    "        # Mask the Array when Computing Spatial Averages\n",
    "        masked_amp = np.ma.masked_where(to_mask == 1,grace_amp)\n",
    "        grace_spatial_avg = np.ma.average(masked_amp,axis=0)\n",
    "        # Convert Back to Numpy Array\n",
    "        grace_spatial_avg = np.ma.filled(grace_spatial_avg,fill_value=0.)\n",
    "        print(('Maximum amplitude (meters): ', np.max(grace_amp)))\n",
    "        print(':: Computing spatial mean.')\n",
    "        # Put Averages into Array | Efficient, but Memory Problems for lots of Dates ...\n",
    "        #grace_spatial_avg_array = np.tile(grace_spatial_avg,(grace_shape[0],1))\n",
    "        # Subtract Spatial Array\n",
    "        for kk in range(0,len(date_list)): # Loop Takes Longer, but Saves on Memory\n",
    "            #grace_amp[:,kk] = np.subtract(grace_amp[:,kk], grace_spatial_avg_array[:,kk])\n",
    "            grace_amp[:,kk] = np.subtract(grace_amp[:,kk], grace_spatial_avg[kk])\n",
    "    grace_spatial_avg_array = grace_spatial_avg = None\n",
    "else: # Spatial then Temporal\n",
    "    # COMPUTE SPATIAL MEAN\n",
    "    if (rm_spatial_mean == True):\n",
    "        # Mask the Array when Computing Spatial Averages\n",
    "        masked_amp = np.ma.masked_where(to_mask == 1,grace_amp)\n",
    "        grace_spatial_avg = np.ma.average(masked_amp,axis=0)\n",
    "        # Convert Back to Numpy Array\n",
    "        grace_spatial_avg = np.ma.filled(grace_spatial_avg,fill_value=0.)\n",
    "        print(':: Computing spatial mean.')\n",
    "        # Put Averages into Array | Efficient, but Memory Problems for lots of Dates ...\n",
    "        #grace_spatial_avg_array = np.tile(grace_spatial_avg,(grace_shape[0],1))\n",
    "        # Subtract Spatial Array\n",
    "        for kk in range(0,len(date_list)): # Loop Takes Longer, but Saves on Memory\n",
    "            #grace_amp[:,kk] = np.subtract(grace_amp[:,kk], grace_spatial_avg_array[:,kk])\n",
    "            grace_amp[:,kk] = np.subtract(grace_amp[:,kk], grace_spatial_avg[kk])\n",
    "    grace_spatial_avg_array = grace_spatial_avg = None\n",
    "    # COMPUTE TEMPORAL MEAN\n",
    "    if (rm_temporal_mean == True):\n",
    "        grace_temporal_avg = np.average(grace_amp,axis=1)\n",
    "        print(':: Computing temporal mean.')\n",
    "        # Put Averages into Array\n",
    "        #grace_temporal_avg_array = np.tile(grace_temporal_avg,(grace_shape[1],1)).T\n",
    "        # Subtract Temporal Array | Efficient, but Memory Problems for lots of Dates ...\n",
    "        for jj in range(0,len(date_list)): # Loop Takes Longer, but Saves on Memory\n",
    "            #grace_amp[:,jj] = np.subtract(grace_amp[:,jj], grace_temporal_avg_array[:,jj])\n",
    "            grace_amp[:,jj] = np.subtract(grace_amp[:,jj], grace_temporal_avg)\n",
    "    grace_temporal_avg_array = grace_temporal_avg = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert to Masked Array (Re-set all masked grid points to zero)<br>\n",
    "asked_amp = np.ma.masked_where(to_mask == 1,grace_amp)<br>\n",
    "rint(':: Masking the amplitude array.')<br>\n",
    "or bb in range(0,len(date_list)): # Loop Takes Longer, but Saves on Memory<br>\n",
    "   grace_amp[:,bb] = np.ma.filled(masked_amp[:,bb],fill_value=0.)<br>\n",
    "   #print(np.max(grace_amp[:,bb]))<br>\n",
    "asked_amp = to_mask = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set Phase to Zero (Amplitudes Contain Phase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grace_pha = np.zeros((360*720,len(date_list)))\n",
    "print(llon)\n",
    "print(llat)\n",
    "print(grace_amp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loop Through Dates and Write to File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for kk in range(0,len(date_list_out)):\n",
    "    \n",
    "    # Output ATML Grid to File for Plotting in GMT\n",
    "    mydt = date_list_out[kk]\n",
    "    # Convert Date to String in YYYY-mm-dd-HH-MM-SS Format\n",
    "    string_date = mydt.strftime('%Y%m%d%H%M%S')\n",
    "    # Locate Date in Full Date List\n",
    "    diff_dates = []\n",
    "    diff_dates_sec = []\n",
    "    for ii in range(0,len(date_list)):\n",
    "        # Find Grace file that matches year, month, and day\n",
    "        diff_dates.append(date_list[ii]-mydt)\n",
    "        diff_dates_sec.append(datetime.timedelta.total_seconds(diff_dates[ii]))\n",
    "    diff_dates_sec = np.asarray(diff_dates_sec)\n",
    "    dselect = np.where(diff_dates_sec == 0.0); dselect = dselect[0]\n",
    "    if (len(dselect > 0)):\n",
    "        dselect = dselect[0]\n",
    "    else:\n",
    "        #print(':: No Date Match Found for Output Date in Range of Amplitude Array | %s' %(string_date))\n",
    "        continue\n",
    "    # Prepare to Write to File\n",
    "    print(':: Writing %s' %(string_dates[dselect]))\n",
    "    grace_out = (\"grace_\" + tag + string_date + \".txt\")\n",
    "    grace_out_nc = (\"grace_\" + tag + string_date + \".nc\")\n",
    "    grace_file = (\"../../output/Grid_Files/GMT/GRACE/height-anomaly_\" + grace_out)\n",
    "    grace_file_pressure = (\"../../output/Grid_Files/GMT/GRACE/pressure_\" + grace_out)\n",
    "    grace_file_nc = (\"../../output/Grid_Files/nc/GRACE/convgf_\" + grace_out_nc)\n",
    "    grace_file_text = (\"../../output/Grid_Files/text/GRACE/convgf_\" + grace_out)\n",
    "    # Prepare Data\n",
    "    all_grace_data = np.column_stack((llon,llat,grace_amp[:,dselect]))\n",
    "    all_grace_data_pressure = np.column_stack((llon,llat,grace_amp[:,dselect]*9.81))\n",
    "    all_grace_data_convgf = np.column_stack((llat,llon,grace_amp[:,dselect],grace_pha[:,dselect]))\n",
    "    # Write Files\n",
    "    if (write_nc == True):\n",
    "        print(\":: Writing netCDF-formatted file.\")\n",
    "        # Open new NetCDF file in \"write\" mode\n",
    "        dataset = netCDF4.Dataset(grace_file_nc,'w',format='NETCDF4_CLASSIC')\n",
    "        # Define dimensions for variables\n",
    "        num_pts = len(llat)\n",
    "        latitude = dataset.createDimension('latitude',num_pts)\n",
    "        longitude = dataset.createDimension('longitude',num_pts)\n",
    "        amplitude = dataset.createDimension('amplitude',num_pts)\n",
    "        phase = dataset.createDimension('phase',num_pts)\n",
    "        # Create variables\n",
    "        latitudes = dataset.createVariable('latitude',float,('latitude',))\n",
    "        longitudes = dataset.createVariable('longitude',float,('longitude',))\n",
    "        amplitudes = dataset.createVariable('amplitude',float,('amplitude',))\n",
    "        phases = dataset.createVariable('phase',float,('phase',))\n",
    "        # Add units\n",
    "        latitudes.units = 'degree_north'\n",
    "        longitudes.units = 'degree_east'\n",
    "        amplitudes.units = 'm'\n",
    "        phases.units = 'degree'\n",
    "        # Assign data\n",
    "        latitudes[:] = llat\n",
    "        longitudes[:] = llon\n",
    "        amplitudes[:] = grace_amp[:,dselect]\n",
    "        phases[:] = grace_pha[:,dselect]\n",
    "        # Write Data to File\n",
    "        dataset.close()\n",
    "    if (write_gmt == True):\n",
    "        print(\":: Writing to GMT-convenient text file.\")\n",
    "        np.savetxt(grace_file, all_grace_data, fmt='%f %f %f')\n",
    "        np.savetxt(grace_file_pressure, all_grace_data_pressure, fmt='%f %f %f')\n",
    "    if (write_txt == True):\n",
    "        print(\":: Writing to plain-text file.\")\n",
    "        np.savetxt(grace_file_text, all_grace_data_convgf, fmt='%f %f %f %f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (write_gmt == True):\n",
    "    print(\":: Writing to GMT-convenient text file.\")\n",
    "    # Compute Standard Deviation for Each Amplitude Pixel\n",
    "    grace_std = np.std(grace_amp,axis=1)\n",
    "    # Export Standard Deviation to File\n",
    "    grace_out = \"grace_std_\" + string_dates[0] + \"_\" + string_dates[-1] + \".txt\"\n",
    "    grace_file = (\"../../output/Grid_Files/GMT/GRACE/height-anomaly_\" + grace_out)\n",
    "    grace_file_pressure = (\"../../output/Grid_Files/GMT/GRACE/pressure_\" + grace_out)\n",
    "    # Prepare Data\n",
    "    #grace_std = np.ma.filled(grace_std,fill_value=0.)\n",
    "    all_grace_data = np.column_stack((llon,llat,grace_std))\n",
    "    all_grace_data_pressure = np.column_stack((llon,llat,grace_std*9.81))\n",
    "    # Write Data to File\n",
    "    np.savetxt(grace_file, all_grace_data, fmt='%f %f %f')\n",
    "    np.savetxt(grace_file_pressure, all_grace_data_pressure, fmt='%f %f %f')\n",
    "\n",
    "    # Compute Maximum for Each Amplitude Pixel\n",
    "    grace_abs = np.absolute(grace_amp)\n",
    "    grace_max = np.amax(grace_abs,axis=1)\n",
    "    # Export Standard Deviation to File\n",
    "    grace_out = \"grace_max_\" + string_dates[0] + \"_\" + string_dates[-1] + \".txt\"\n",
    "    grace_file = (\"../../output/Grid_Files/GMT/GRACE/height-anomaly_\" + grace_out)\n",
    "    grace_file_pressure = (\"../../output/Grid_Files/GMT/GRACE/pressure_\" + grace_out)\n",
    "    # Prepare Data\n",
    "    all_grace_data = np.column_stack((llon,llat,grace_max))\n",
    "    all_grace_data_pressure = np.column_stack((llon,llat,grace_max*9.81))\n",
    "    # Write Data to File\n",
    "    np.savetxt(grace_file, all_grace_data, fmt='%f %f %f')\n",
    "    np.savetxt(grace_file_pressure, all_grace_data_pressure, fmt='%f %f %f')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------- END CODE --------------------------- #"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
