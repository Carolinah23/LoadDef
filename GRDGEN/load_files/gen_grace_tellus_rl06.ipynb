{"cells": [{"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["#!/usr/bin/env python"]}, {"cell_type": "markdown", "metadata": {}, "source": ["*********************************************************************<br>\n", "PROGRAM TO GENERATE GRIDS FOR LOADS FROM GRACE<br>\n", ":: GRIDS GENERATED MAY BE USED BY LOADDEF (run_cn.py) OR IN GMT<br>\n", "<br>\n", "Copyright (c) 2014-2019: HILARY R. MARTENS, LUIS RIVERA, MARK SIMONS         <br>\n", "<br>\n", "This file is part of LoadDef.<br>\n", "<br>\n", "   LoadDef is free software: you can redistribute it and/or modify<br>\n", "   it under the terms of the GNU General Public License as published by<br>\n", "   the Free Software Foundation, either version 3 of the License, or<br>\n", "   any later version.<br>\n", "<br>\n", "   LoadDef is distributed in the hope that it will be useful,<br>\n", "   but WITHOUT ANY WARRANTY; without even the implied warranty of<br>\n", "   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the<br>\n", "   GNU General Public License for more details.<br>\n", "<br>\n", "   You should have received a copy of the GNU General Public License<br>\n", "   along with LoadDef.  If not, see <https://www.gnu.org/licenses/>.<br>\n", "<br>\n", "*********************************************************************"]}, {"cell_type": "markdown", "metadata": {}, "source": ["MODIFY PYTHON PATH TO INCLUDE 'CONVGF' DIRECTORY"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from __future__ import print_function\n", "import sys\n", "import os\n", "sys.path.append(os.getcwd() + \"/../../\")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["IMPORT PYTHON MODULES"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import numpy as np\n", "import scipy as sc\n", "import datetime\n", "import netCDF4 \n", "from GRDGEN.utility import read_grace_tellus"]}, {"cell_type": "markdown", "metadata": {}, "source": ["--------------- SPECIFY USER INPUTS --------------------- #"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Atmospheric Surface Pressure Files from GRACE - MUST HAVE NETCDF4 FOR PYTHON INSTALLED <br>\n", " Specify the directory containing the yearly netcdf files here:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["grace_directory = (\"../../input/Load_Models/GRACE-Tellus-RL06/\")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Date Range for Temporal-Mean Computation (yyyy, mm, dd); End Day is Included (Files to be Read in)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["start_year_tm = 2019; start_month_tm = 10; start_day_tm = 1\n", "end_year_tm = 2021; end_month_tm = 10; end_day_tm = 1\n", "  \n", "# Date Range for Output Files (yyyy, mm, dd); End Day is Included (Files to be Written out)\n", "start_year_out = 2019; start_month_out = 10; start_day_out = 1\n", "end_year_out = 2021; end_month_out = 10; end_day_out = 1\n", "  \n", "# Remove spatial and temporal averages?\n", "rm_spatial_mean = False\n", "rm_temporal_mean = False"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Order in which to remove the temporal (t) and spatial (s) averages (false = t then s; true = s then t)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["flip = False"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Additional Name Tag"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["tmrange = \"%4d%02d%02d-%4d%02d%02d\" % (start_year_tm, start_month_tm, start_day_tm, end_year_tm, end_month_tm, end_day_tm)\n", "add_tag = (tmrange + \"_GRACE_Tellus_RL06\")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["# Complete Pathname to Current GRACE File"]}, {"cell_type": "markdown", "metadata": {}, "source": ["First solution"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["loadfile1 = grace_directory + \"GRCTellus.JPL.200204_202201.GLO.RL06M.MSCNv02CRI.nc\"\n", "tag1 = \"JPL\"\n", " \n", "# Second solution\n", "loadfile2 = None \n", "tag2 = \"\""]}, {"cell_type": "markdown", "metadata": {}, "source": ["Third solution"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["loadfile3 = None\n", "tag3 = \"\""]}, {"cell_type": "markdown", "metadata": {}, "source": ["Scaling factors"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["scaling = None"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Average solutions"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["avgsol = False"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Apply GRACE scaling factors"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["appscl = False"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Solution tag"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["if (avgsol == True):\n", "    soltag = (tag1 + \"-\" + tag2 + \"-\" + tag3)\n", "else:\n", "    soltag = (tag1)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Write Load Information to a netCDF-formatted File? (Default for convolution)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["write_nc = True"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Write Load Information to a Text File? (Alternative for convolution)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["write_txt = False"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Write Load Information to a GMT-formatted File?"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["write_gmt = False"]}, {"cell_type": "markdown", "metadata": {}, "source": ["------------------ END USER INPUTS ----------------------- #"]}, {"cell_type": "markdown", "metadata": {}, "source": ["-------------------- BEGIN CODE -------------------------- #"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Check for output of a file"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["if (write_nc == False) and (write_txt == False) and (write_gmt == False):\n", "    print(\":: Error: No output file(s) selected. Options: netCDF, GMT, and/or plain-text.\")\n", "    sys.exit()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Create Folders"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["if not (os.path.isdir(\"../../output/Grid_Files/\")):\n", "    os.makedirs(\"../../output/Grid_Files/\")\n", "if not (os.path.isdir(\"../../output/Grid_Files/GMT/\")):\n", "    os.makedirs(\"../../output/Grid_Files/GMT/\")\n", "if not (os.path.isdir(\"../../output/Grid_Files/GMT/GRACE/\")):\n", "    os.makedirs(\"../../output/Grid_Files/GMT/GRACE/\")\n", "if not (os.path.isdir(\"../../output/Grid_Files/nc/\")):\n", "    os.makedirs(\"../../output/Grid_Files/nc/\")\n", "if not (os.path.isdir(\"../../output/Grid_Files/nc/GRACE/\")):\n", "    os.makedirs(\"../../output/Grid_Files/nc/GRACE/\")\n", "if not (os.path.isdir(\"../../output/Grid_Files/text/\")):\n", "    os.makedirs(\"../../output/Grid_Files/text/\")\n", "if not (os.path.isdir(\"../../output/Grid_Files/text/GRACE/\")):\n", "    os.makedirs(\"../../output/Grid_Files/text/GRACE/\")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Filename Tags"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["if (flip == False): # temporal then spatial\n", "    tag = (\"rmTM1\" + str(rm_temporal_mean) + \"_rmSM2\" + str(rm_spatial_mean) + \"_\" + add_tag + \"_\" + soltag + \"_Scaling\" + str(appscl) + \"_\")\n", "else: # spatial then temporal\n", "    tag = (\"rmSM1\" + str(rm_spatial_mean) + \"_rmTM2\" + str(rm_temporal_mean) + \"_\" + add_tag + \"_\" + soltag + \"_Scaling\" + str(appscl) + \"_\")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Determine Ordinal Dates for Temporal Mean Calculation"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["mydate1 = datetime.datetime(start_year_tm, start_month_tm, start_day_tm, 0, 0, 0) #start_date = datetime.date.toordinal(mydate1)\n", "mydate2 = datetime.datetime(end_year_tm, end_month_tm, end_day_tm, 0, 0, 0) #end_date = datetime.date.toordinal(mydate2)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Determine Date Range (From Start to End, Increasing by 1 day; sometimes GRACE has two models per month)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["curr = mydate1\n", "date_list = []\n", "date_list.append(curr)\n", "count = 0\n", "while curr < mydate2:\n", "    curr += datetime.timedelta(days=1)\n", "    date_list.append(curr)\n", "# Determine Date Range (From Start to End, Increasing by 30 days)\n", "#    count = count+1\n", "#    if ((start_month_tm + count) == 13):\n", "#        start_year_tm += 1\n", "#        start_month_tm = 1\n", "#        count = 0\n", "#    curr = datetime.datetime(start_year_tm, (start_month_tm + count), 1,0,0,0)\n", "#    date_list.append(curr)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Determine Ordinal Dates for Output"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["mydate1 = datetime.datetime(start_year_out, start_month_out, start_day_out, 0, 0, 0)\n", "mydate2 = datetime.datetime(end_year_out, end_month_out, end_day_out, 0, 0, 0)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Determine Date Range (From Start to End, Increasing by 1 day; sometimes GRACE has two models per month)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["curr = mydate1\n", "date_list_out = []\n", "date_list_out.append(curr)\n", "count = 0\n", "while curr < mydate2:\n", "    curr += datetime.timedelta(days=1)\n", "    date_list_out.append(curr)\n", "# Determine Date Range (From Start to End, Increasing by 30 days)\n", "#    count = count+1\n", "#    if ((start_month_out + count) == 13):\n", "#        start_year_out += 1\n", "#        start_month_out = 1\n", "#        count = 0\n", "#    curr = datetime.datetime(start_year_out, (start_month_out + count), 1,0,0,0)\n", "#    date_list_out.append(curr)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Determine Number of Dates for Temporal Mean"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["if isinstance(date_list,float) == True:\n", "    numel = 1\n", "else: \n", "    numel = len(date_list)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Determine Number of Dates for Output"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["if isinstance(date_list_out,float) == True:\n", "    numel_out = 1\n", "else:\n", "    numel_out = len(date_list_out)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Check Number of Dates"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["if (numel_out > numel):\n", "    print(':: Warning: Fewer Dates for the Temporal Mean Computation than for the Output Files.')\n", "elif (min(date_list) > min(date_list_out)):\n", "    print(':: Warning: Dates for Output Files are Outside the Range of the Files to be Read in.')\n", "elif (max(date_list) < max(date_list_out)):\n", "    print(':: Warning: Dates for Output Files are Outside the Range of the Files to be Read in.')"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Create Array of String Dates"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["string_dates = []\n", "for qq in range(0,numel):\n", "    mydt = date_list[qq]\n", "    string_dates.append(mydt.strftime('%Y%m%d%H%M%S'))"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Fill Amplitude Array"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["to_mask = np.empty((360*720,len(date_list)))\n", "grace_amp = np.empty((360*720,len(date_list)))\n", "dates_to_delete = []\n", "# SHAPE OF ARRAY\n", "grace_shape = grace_amp.shape\n", "# Loop Through Dates\n", "for ii in range(0,len(date_list)):\n", "    mydt = date_list[ii] \n", "    string_date = mydt.strftime('%Y%m%d%H%M%S') # Convert Date to String in YYYY-mm-dd-HH-MM-SS Format\n", "    print(':: Reading %s' %(string_date))\n", "    string_year = mydt.strftime('%Y') # Convert Date to String in YYYY Format\n", "    \n", "    # Read the File \n", "    if (os.path.isfile(loadfile1)):\n", "        llat,llon,amp,pha,llat1dseq,llon1dseq,amp2darr,pha2darr = read_grace_tellus.main(loadfile1,mydt,ldfl2=loadfile2,ldfl3=loadfile3,scl=scaling,avsolns=avgsol,appscaling=appscl)\n", "        if llat is None:\n", "            print(':: Warning: Date does not exist within file.')\n", "            # Save date_list index, then continue\n", "            dates_to_delete.append(ii)\n", "            continue\n", "            #to_mask[:,ii] = np.ones((grace_shape[0],)) # set mask to true\n", "            #grace_amp[:,ii] = np.zeros((grace_shape[0],))\n", "        # Combine Amplitude and Phase \n", "        else:\n", "            to_mask[:,ii] = np.zeros((grace_shape[0],))\n", "            grace_amp[:,ii] = np.multiply(amp,np.cos(np.radians(pha)))\n", "            lat_array = llat.copy()\n", "            lon_array = llon.copy()\n", "            print(grace_amp.shape)\n", "    else: # File Does Not Exist\n", "        print(':: Warning: Load File Does Not Exist.')\n", "        #to_mask[:,ii] = np.ones((grace_shape[0],)) # set mask to true\n", "        #grace_amp[:,ii] = np.zeros((grace_shape[0],))"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Delete dates with no data"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["date_list = np.delete(date_list,dates_to_delete)\n", "string_dates = np.delete(string_dates,dates_to_delete)\n", "grace_amp = np.delete(grace_amp,dates_to_delete,axis=1)\n", "to_mask = np.delete(to_mask,dates_to_delete,axis=1)\n", "llat = lat_array.copy(); llon = lon_array.copy()\n", "print(grace_amp.shape)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Order of Removing the Temporal and Spatial Means"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["if (flip == False): # Temporal then Spatial\n", "    # COMPUTE TEMPORAL MEAN\n", "    if (rm_temporal_mean == True):\n", "        grace_temporal_avg = np.average(grace_amp,axis=1)\n", "        print(('Maximum amplitude (meters): ', np.max(grace_amp)))\n", "        print(':: Computing temporal mean.')\n", "        # Put Averages into Array | Efficient, but Memory Problems for lots of Dates ...\n", "        #grace_temporal_avg_array = np.tile(grace_temporal_avg,(grace_shape[1],1)).T\n", "        # Subtract Temporal Array\n", "        for jj in range(0,len(date_list)): # Loop Takes Longer, but Saves on Memory\n", "            #grace_amp[:,jj] = np.subtract(grace_amp[:,jj], grace_temporal_avg_array[:,jj])\n", "            #print(max(grace_amp[:,jj]))            \n", "            grace_amp[:,jj] = np.subtract(grace_amp[:,jj], grace_temporal_avg)\n", "            #print(max(grace_amp[:,jj])) \n", "        #print(grace_temporal_avg)\n", "        #print(grace_amp)\n", "    grace_temporal_avg_array = grace_temporal_avg = None\n", "    # COMPUTE SPATIAL MEAN\n", "    if (rm_spatial_mean == True):\n", "        # Mask the Array when Computing Spatial Averages\n", "        masked_amp = np.ma.masked_where(to_mask == 1,grace_amp)\n", "        grace_spatial_avg = np.ma.average(masked_amp,axis=0)\n", "        # Convert Back to Numpy Array\n", "        grace_spatial_avg = np.ma.filled(grace_spatial_avg,fill_value=0.)\n", "        print(('Maximum amplitude (meters): ', np.max(grace_amp)))\n", "        print(':: Computing spatial mean.')\n", "        # Put Averages into Array | Efficient, but Memory Problems for lots of Dates ...\n", "        #grace_spatial_avg_array = np.tile(grace_spatial_avg,(grace_shape[0],1))\n", "        # Subtract Spatial Array\n", "        for kk in range(0,len(date_list)): # Loop Takes Longer, but Saves on Memory\n", "            #grace_amp[:,kk] = np.subtract(grace_amp[:,kk], grace_spatial_avg_array[:,kk])\n", "            grace_amp[:,kk] = np.subtract(grace_amp[:,kk], grace_spatial_avg[kk])\n", "    grace_spatial_avg_array = grace_spatial_avg = None\n", "else: # Spatial then Temporal\n", "    # COMPUTE SPATIAL MEAN\n", "    if (rm_spatial_mean == True):\n", "        # Mask the Array when Computing Spatial Averages\n", "        masked_amp = np.ma.masked_where(to_mask == 1,grace_amp)\n", "        grace_spatial_avg = np.ma.average(masked_amp,axis=0)\n", "        # Convert Back to Numpy Array\n", "        grace_spatial_avg = np.ma.filled(grace_spatial_avg,fill_value=0.)\n", "        print(':: Computing spatial mean.')\n", "        # Put Averages into Array | Efficient, but Memory Problems for lots of Dates ...\n", "        #grace_spatial_avg_array = np.tile(grace_spatial_avg,(grace_shape[0],1))\n", "        # Subtract Spatial Array\n", "        for kk in range(0,len(date_list)): # Loop Takes Longer, but Saves on Memory\n", "            #grace_amp[:,kk] = np.subtract(grace_amp[:,kk], grace_spatial_avg_array[:,kk])\n", "            grace_amp[:,kk] = np.subtract(grace_amp[:,kk], grace_spatial_avg[kk])\n", "    grace_spatial_avg_array = grace_spatial_avg = None\n", "    # COMPUTE TEMPORAL MEAN\n", "    if (rm_temporal_mean == True):\n", "        grace_temporal_avg = np.average(grace_amp,axis=1)\n", "        print(':: Computing temporal mean.')\n", "        # Put Averages into Array\n", "        #grace_temporal_avg_array = np.tile(grace_temporal_avg,(grace_shape[1],1)).T\n", "        # Subtract Temporal Array | Efficient, but Memory Problems for lots of Dates ...\n", "        for jj in range(0,len(date_list)): # Loop Takes Longer, but Saves on Memory\n", "            #grace_amp[:,jj] = np.subtract(grace_amp[:,jj], grace_temporal_avg_array[:,jj])\n", "            grace_amp[:,jj] = np.subtract(grace_amp[:,jj], grace_temporal_avg)\n", "    grace_temporal_avg_array = grace_temporal_avg = None"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Convert to Masked Array (Re-set all masked grid points to zero)<br>\n", "asked_amp = np.ma.masked_where(to_mask == 1,grace_amp)<br>\n", "rint(':: Masking the amplitude array.')<br>\n", "or bb in range(0,len(date_list)): # Loop Takes Longer, but Saves on Memory<br>\n", "   grace_amp[:,bb] = np.ma.filled(masked_amp[:,bb],fill_value=0.)<br>\n", "   #print(np.max(grace_amp[:,bb]))<br>\n", "asked_amp = to_mask = None"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Set Phase to Zero (Amplitudes Contain Phase)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["grace_pha = np.zeros((360*720,len(date_list)))\n", "print(llon)\n", "print(llat)\n", "print(grace_amp)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Loop Through Dates and Write to File"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["for kk in range(0,len(date_list_out)):\n", "    \n", "    # Output ATML Grid to File for Plotting in GMT\n", "    mydt = date_list_out[kk]\n", "    # Convert Date to String in YYYY-mm-dd-HH-MM-SS Format\n", "    string_date = mydt.strftime('%Y%m%d%H%M%S')\n", "    # Locate Date in Full Date List\n", "    diff_dates = []\n", "    diff_dates_sec = []\n", "    for ii in range(0,len(date_list)):\n", "        # Find Grace file that matches year, month, and day\n", "        diff_dates.append(date_list[ii]-mydt)\n", "        diff_dates_sec.append(datetime.timedelta.total_seconds(diff_dates[ii]))\n", "    diff_dates_sec = np.asarray(diff_dates_sec)\n", "    dselect = np.where(diff_dates_sec == 0.0); dselect = dselect[0]\n", "    if (len(dselect > 0)):\n", "        dselect = dselect[0]\n", "    else:\n", "        print(':: Warning: No Date Match Found for Output Date in Range of Amplitude Array | %s' %(string_date))\n", "        continue\n", "    #idx = str(jj) # Convert to string to test if a value exists (including zero)\n", "    #if not idx:\n", "    #    print(':: Warning: No Date Match Found for Output Date in Range of Amplitude Array | %s' %(string_date))\n", "    #    continue\n", "    #jj = int(idx) # Convert back to integer to use as index\n", "    # Prepare to Write to File\n", "    print(':: Writing %s' %(string_dates[dselect]))\n", "    grace_out = (\"grace_\" + tag + string_date + \".txt\")\n", "    grace_out_nc = (\"grace_\" + tag + string_date + \".nc\")\n", "    grace_file = (\"../../output/Grid_Files/GMT/GRACE/height-anomaly_\" + grace_out)\n", "    grace_file_pressure = (\"../../output/Grid_Files/GMT/GRACE/pressure_\" + grace_out)\n", "    grace_file_nc = (\"../../output/Grid_Files/nc/GRACE/convgf_\" + grace_out_nc)\n", "    grace_file_text = (\"../../output/Grid_Files/text/GRACE/convgf_\" + grace_out)\n", "    # Prepare Data\n", "    all_grace_data = np.column_stack((llon,llat,grace_amp[:,dselect]))\n", "    all_grace_data_pressure = np.column_stack((llon,llat,grace_amp[:,dselect]*9.81))\n", "    all_grace_data_convgf = np.column_stack((llat,llon,grace_amp[:,dselect],grace_pha[:,dselect]))\n", "    # Write Files\n", "    if (write_nc == True):\n", "        print(\":: Writing netCDF-formatted file.\")\n", "        # Open new NetCDF file in \"write\" mode\n", "        dataset = netCDF4.Dataset(grace_file_nc,'w',format='NETCDF4_CLASSIC')\n", "        # Define dimensions for variables\n", "        num_pts = len(llat)\n", "        latitude = dataset.createDimension('latitude',num_pts)\n", "        longitude = dataset.createDimension('longitude',num_pts)\n", "        amplitude = dataset.createDimension('amplitude',num_pts)\n", "        phase = dataset.createDimension('phase',num_pts)\n", "        # Create variables\n", "        latitudes = dataset.createVariable('latitude',float,('latitude',))\n", "        longitudes = dataset.createVariable('longitude',float,('longitude',))\n", "        amplitudes = dataset.createVariable('amplitude',float,('amplitude',))\n", "        phases = dataset.createVariable('phase',float,('phase',))\n", "        # Add units\n", "        latitudes.units = 'degree_north'\n", "        longitudes.units = 'degree_east'\n", "        amplitudes.units = 'm'\n", "        phases.units = 'degree'\n", "        # Assign data\n", "        latitudes[:] = llat\n", "        longitudes[:] = llon\n", "        amplitudes[:] = grace_amp[:,dselect]\n", "        phases[:] = grace_pha[:,dselect]\n", "        # Write Data to File\n", "        dataset.close()\n", "    if (write_gmt == True):\n", "        print(\":: Writing to GMT-convenient text file.\")\n", "        np.savetxt(grace_file, all_grace_data, fmt='%f %f %f')\n", "        np.savetxt(grace_file_pressure, all_grace_data_pressure, fmt='%f %f %f')\n", "    if (write_txt == True):\n", "        print(\":: Writing to plain-text file.\")\n", "        np.savetxt(grace_file_text, all_grace_data_convgf, fmt='%f %f %f %f')"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["if (write_gmt == True):\n", "    print(\":: Writing to GMT-convenient text file.\")\n", "    # Compute Standard Deviation for Each Amplitude Pixel\n", "    grace_std = np.std(grace_amp,axis=1)\n", "    # Export Standard Deviation to File\n", "    grace_out = \"grace_std_\" + string_dates[0] + \"_\" + string_dates[-1] + \".txt\"\n", "    grace_file = (\"../../output/Grid_Files/GMT/GRACE/height-anomaly_\" + grace_out)\n", "    grace_file_pressure = (\"../../output/Grid_Files/GMT/GRACE/pressure_\" + grace_out)\n", "    # Prepare Data\n", "    #grace_std = np.ma.filled(grace_std,fill_value=0.)\n", "    all_grace_data = np.column_stack((llon,llat,grace_std))\n", "    all_grace_data_pressure = np.column_stack((llon,llat,grace_std*9.81))\n", "    # Write Data to File\n", "    np.savetxt(grace_file, all_grace_data, fmt='%f %f %f')\n", "    np.savetxt(grace_file_pressure, all_grace_data_pressure, fmt='%f %f %f')\n\n", "    # Compute Maximum for Each Amplitude Pixel\n", "    grace_abs = np.absolute(grace_amp)\n", "    grace_max = np.amax(grace_abs,axis=1)\n", "    # Export Standard Deviation to File\n", "    grace_out = \"grace_max_\" + string_dates[0] + \"_\" + string_dates[-1] + \".txt\"\n", "    grace_file = (\"../../output/Grid_Files/GMT/GRACE/height-anomaly_\" + grace_out)\n", "    grace_file_pressure = (\"../../output/Grid_Files/GMT/GRACE/pressure_\" + grace_out)\n", "    # Prepare Data\n", "    all_grace_data = np.column_stack((llon,llat,grace_max))\n", "    all_grace_data_pressure = np.column_stack((llon,llat,grace_max*9.81))\n", "    # Write Data to File\n", "    np.savetxt(grace_file, all_grace_data, fmt='%f %f %f')\n", "    np.savetxt(grace_file_pressure, all_grace_data_pressure, fmt='%f %f %f')"]}, {"cell_type": "markdown", "metadata": {}, "source": ["--------------------- END CODE --------------------------- #"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.6.4"}}, "nbformat": 4, "nbformat_minor": 2}