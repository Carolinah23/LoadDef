{"cells": [{"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["#!/usr/bin/env python"]}, {"cell_type": "markdown", "metadata": {}, "source": ["*********************************************************************<br>\n", "MAIN PROGRAM TO COMPUTE A DESIGN MATRIX TO INVERT FOR SURFACE LOAD --<br>\n", "BY CONVOLVING DISPLACEMENT LOAD GREENS FUNCTIONS WITH A UNIFORM LOAD IN <br>\n", "EACH USER-DEFINED GRID CELL <br>\n", "<br>\n", "Copyright (c) 2014-2022: HILARY R. MARTENS, LUIS RIVERA, MARK SIMONS         <br>\n", "<br>\n", "This file is part of LoadDef.<br>\n", "<br>\n", "   LoadDef is free software: you can redistribute it and/or modify<br>\n", "   it under the terms of the GNU General Public License as published by<br>\n", "   the Free Software Foundation, either version 3 of the License, or<br>\n", "   any later version.<br>\n", "<br>\n", "   LoadDef is distributed in the hope that it will be useful,<br>\n", "   but WITHOUT ANY WARRANTY; without even the implied warranty of<br>\n", "   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the<br>\n", "   GNU General Public License for more details.<br>\n", "<br>\n", "   You should have received a copy of the GNU General Public License<br>\n", "   along with LoadDef.  If not, see <https://www.gnu.org/licenses/>.<br>\n", "<br>\n", "*********************************************************************"]}, {"cell_type": "markdown", "metadata": {}, "source": ["IMPORT PRINT FUNCTION"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from __future__ import print_function"]}, {"cell_type": "markdown", "metadata": {}, "source": ["IMPORT MPI MODULE"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from mpi4py import MPI"]}, {"cell_type": "markdown", "metadata": {}, "source": ["MODIFY PYTHON PATH TO INCLUDE 'LoadDef' DIRECTORY"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import sys\n", "import os\n", "sys.path.append(os.getcwd() + \"/../\")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["IMPORT PYTHON MODULES"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import numpy as np\n", "import scipy as sc\n", "import datetime\n", "import netCDF4 \n", "from CONVGF.CN import load_convolution\n", "from CONVGF.utility import read_station_file\n", "from CONVGF.utility import read_lsmask"]}, {"cell_type": "markdown", "metadata": {}, "source": ["--------------- SPECIFY USER INPUTS --------------------- #"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Reference Frame (used for filenames) [Blewitt 2003]"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["rfm = \"cf\""]}, {"cell_type": "markdown", "metadata": {}, "source": ["Greens Function File<br>\n", " :: May be load Green's function file output directly from run_gf.py (norm_flag = False)<br>\n", " :: May be from a published table, normalized according to Farrell (1972) conventions [theta, u_norm, v_norm]"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["pmod = \"PREM\"\n", "grn_file = (\"../output/Greens_Functions/\" + rfm + \"_\" + pmod + \".txt\")\n", "norm_flag  = False"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Full Path to Grid File Containing Cells<br>\n", " :: Format: south lat [float], north lat [float], west lon [float], east lon [float], unique cell id [string]"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["gridname = (\"cells_44.0_46.0_247.0_249.0_0.25\")\n", "#gridname = (\"cells_31.0_49.5_234.0_256.0_0.25\")\n", "loadgrid = (\"../output/Grid_Files/nc/cells/\" + gridname + \".nc\") "]}, {"cell_type": "markdown", "metadata": {}, "source": ["Load Density<br>\n", " Recommended: 1000 kg/m^3 as a standard for inversion"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["ldens = 1000.0\n", "  \n", "# Ocean/Land Mask \n", "#  :: 0 = do not mask ocean or land (retain full model); 1 = mask out land (retain ocean); 2 = mask out oceans (retain land)\n", "#  :: Recommended: 1 for oceanic; 2 for atmospheric and continental water\n", "lsmask_type = 0"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Full Path to Land-Sea Mask File (May be Irregular and Sparse)<br>\n", " :: Format: Lat, Lon, Mask [0=ocean; 1=land]"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["lsmask_file = (\"../input/Land_Sea/ETOPO1_Ice_g_gmt4_wADD.txt\")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Station/Grid-Point Location File (Lat, Lon, StationName)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["sta_file_name = (\"NOTA_Select\")\n", "sta_file = (\"../input/Station_Locations/\" + sta_file_name + \".txt\")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Optional: Additional string to include in output filenames (e.g. \"_2019\")"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["outstr = (pmod + \"_\" + gridname + \"_\" + sta_file_name)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["------------------ END USER INPUTS ----------------------- #"]}, {"cell_type": "markdown", "metadata": {}, "source": ["-------------------- SETUP MPI --------------------------- #"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Get the Main MPI Communicator That Controls Communication Between Processors"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["comm = MPI.COMM_WORLD\n", "# Get My \"Rank\", i.e. the Processor Number Assigned to Me\n", "rank = comm.Get_rank()\n", "# Get the Total Number of Other Processors Used\n", "size = comm.Get_size()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["---------------------------------------------------------- #"]}, {"cell_type": "markdown", "metadata": {}, "source": ["-------------------- BEGIN CODE -------------------------- #"]}, {"cell_type": "markdown", "metadata": {}, "source": ["LoadFile Format (\"bbox\" tells the software to read the text file line by line for individual bounding-box cells in the load grid)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["loadfile_format = \"bbox\""]}, {"cell_type": "markdown", "metadata": {}, "source": ["Bounding boxes for grid cells are regular in lat/lon"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["regular = True"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Check for existence of load grid"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["if not os.path.isfile(loadgrid):\n", "    sys.exit('Error: The load grid does not exist. You may need to create it.')"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Put loadgrid file into a list (for consistency with how traditional load files are treated)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["load_files = []\n", "load_files.append(loadgrid)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Ensure that the Output Directories Exist"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["if (rank == 0):\n", "    if not (os.path.isdir(\"../output/Convolution/\")):\n", "        os.makedirs(\"../output/Convolution/\")\n", "    if not (os.path.isdir(\"../output/DesignMatrixLoad/\")):\n", "        os.makedirs(\"../output/DesignMatrixLoad/\")\n", "    if not (os.path.isdir(\"../output/Figures/\")):\n", "        os.makedirs(\"../output/Figures/\")\n\n", "    # Read Station & Date Range File\n", "    lat,lon,sta = read_station_file.main(sta_file)\n\n", "    # Determine Number of Stations Read In\n", "    if isinstance(lat,float) == True: # only 1 station\n", "        numel = 1\n", "    else:\n", "        numel = len(lat)\n\n", "    # Read in the Land-Sea Mask\n", "    if (lsmask_type > 0):\n", "        lslat,lslon,lsmask = read_lsmask.main(lsmask_file)\n", "    else:\n", "        # Doesn't really matter so long as there are some values filled in with something other than 1 or 2\n", "        lat1d = np.arange(-90.,90.,2.)\n", "        lon1d = np.arange(0.,360.,2.)\n", "        olon,olat = np.meshgrid(lon1d,lat1d)\n", "        lslat = olat.flatten()\n", "        lslon = olon.flatten()\n", "        lsmask = np.ones((len(lslat),)) * -1.\n\n", "    # Ensure that Land-Sea Mask Longitudes are in Range 0-360\n", "    neglon_idx = np.where(lslon<0.)\n", "    lslon[neglon_idx] = lslon[neglon_idx] + 360.\n", " \n", "    # Read in the loadgrid\n", "    lcext = loadgrid[-2::]\n", "    if (lcext == 'xt'):\n", "        load_cells = np.loadtxt(loadgrid,usecols=(4,),unpack=True,dtype='U')\n", "        lcslat,lcnlat,lcwlon,lcelon = np.loadtxt(loadgrid,usecols=(0,1,2,3),unpack=True)\n", "    elif (lcext == 'nc'):\n", "        f = netCDF4.Dataset(loadgrid)\n", "        load_cells = f.variables['cell_ids'][:]\n", "        lcslat = f.variables['slatitude'][:]\n", "        lcnlat = f.variables['nlatitude'][:]\n", "        lcwlon = f.variables['wlongitude'][:]\n", "        lcelon = f.variables['elongitude'][:]\n", "        f.close()    \n", "    # Ensure that Bounding Box Longitudes are in Range 0-360\n", "    for yy in range(0,len(lcwlon)):\n", "        if (lcwlon[yy] < 0.):\n", "            lcwlon[yy] += 360.\n", "        if (lcelon[yy] < 0.):\n", "            lcelon[yy] += 360.\n", "    # Compute center of each load cell\n", "    print(':: Warning: Computing center of load cells. Special consideration should be made for cells spanning the prime meridian, if applicable.')\n", "    lclat = (lcslat + lcnlat)/2.\n", "    lclon = (lcwlon + lcelon)/2.\n", "# If I'm a Worker, I Know Nothing About the Data\n", "else:\n", "    load_cells = lclat = lclon = lslat = lslon = lsmask = sta = lat = lon = numel = None "]}, {"cell_type": "markdown", "metadata": {}, "source": ["All Processors Get Certain Arrays and Parameters; Broadcast Them"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["load_cells  = comm.bcast(load_cells, root=0)\n", "lclat       = comm.bcast(lclat, root=0)\n", "lclon       = comm.bcast(lclon, root=0)\n", "lslat       = comm.bcast(lslat, root=0)\n", "lslon       = comm.bcast(lslon, root=0)\n", "lsmask      = comm.bcast(lsmask, root=0)\n", "sta         = comm.bcast(sta, root=0)\n", "lat         = comm.bcast(lat, root=0)\n", "lon         = comm.bcast(lon, root=0)\n", "numel       = comm.bcast(numel, root=0)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Determine the Chunk Sizes for the Convolution"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["total_cells = len(load_cells)\n", "nominal_load = total_cells // size # Floor Divide\n", "# Final Chunk Might Be Different in Size Than the Nominal Load\n", "if rank == size - 1:\n", "    procN = total_cells - rank * nominal_load\n", "else:\n", "    procN = nominal_load"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Set up Design matrix (rows = stations[e,n,u]; columns = load cells)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["if (rank == 0):\n", "    desmat = np.zeros((numel*3, total_cells)) # Multiplication by 3 for 3 spatial dimensions (e,n,u)\n", "    dmrows = np.empty((numel*3,),dtype='U10') # Assumes that station names are no more than 9 characters in length (with E, N, or U also appended)\n", "    sclat = np.zeros((numel*3,))\n", "    sclon = np.zeros((numel*3,))"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Loop Through Each Station"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["for jj in range(0,numel):\n\n", "    # Remove Index If Only 1 Station\n", "    if (numel == 1): # only 1 station read in\n", "        my_sta = sta\n", "        my_lat = lat\n", "        my_lon = lon\n", "    else:\n", "        my_sta = sta[jj]\n", "        my_lat = lat[jj]\n", "        my_lon = lon[jj]\n\n", "    # If Rank is Master, Output Station Name\n", "    try: \n", "        my_sta = my_sta.decode()\n", "    except: \n", "        if (rank == 0):\n", "            print(':: No need to decode station.')\n", "    if (rank == 0):\n", "        print(' ')\n", "        print(':: Starting on Station: ' + my_sta)\n\n", "    # Output File Name\n", "    cnv_out = (my_sta + \"_\" + rfm + \"_\" + outstr + \".txt\")\n\n", "    # Set Lat/Lon/Name for Current Station\n", "    slat = my_lat\n", "    slon = my_lon\n", "    sname = my_sta\n\n", "    # Adjust longitude, if necessary\n", "    if (slon < 0.):\n", "        slon += 360.\n\n", "    # Perform the Convolution for Each Station\n", "    #### NOTE: Mesh defaults are adjusted to ensure we get a good number of points within each grid cell to adequately represent the shape of each cell\n", "    if (rank == 0):\n", "        print(\":: General Warning: Use caution when selecting mesh parameters. For small cells and distant stations, there is a possibility that no mesh points will lie within the distant cell. Please adapt settings to your application. [run_dm.py]\")\n", "        eamp,epha,namp,npha,vamp,vpha = load_convolution.main(grn_file,norm_flag,load_files,regular,lslat,lslon,lsmask,\\\n", "            slat,slon,sname,cnv_out,lsmask_type,loadfile_format,rank,procN,comm,load_density=ldens,azminc=0.5,delinc3=0.005,delinc4=0.02,delinc5=0.05)\n", "    # For Worker Ranks, Run the Code But Don't Return Any Variables\n", "    else:\n", "        load_convolution.main(grn_file,norm_flag,load_files,regular,lslat,lslon,lsmask,\\\n", "            slat,slon,sname,cnv_out,lsmask_type,loadfile_format,rank,procN,comm,load_density=ldens,azminc=0.5,delinc3=0.005,delinc4=0.02,delinc5=0.05)\n\n", "    # Make Sure All Jobs Have Finished Before Continuing\n", "    comm.Barrier()\n", " \n", "    if (rank == 0):\n\n", "        # Convert Amp/Pha to Displacement\n", "        edisp = np.multiply(eamp,np.cos(np.multiply(epha,(np.pi/180.))))\n", "        ndisp = np.multiply(namp,np.cos(np.multiply(npha,(np.pi/180.))))\n", "        udisp = np.multiply(vamp,np.cos(np.multiply(vpha,(np.pi/180.))))\n\n", "        # Fill in Design Matrix\n", "        idxe = (jj*3)+0\n", "        idxn = (jj*3)+1\n", "        idxu = (jj*3)+2\n", "        desmat[idxe,:] = edisp\n", "        desmat[idxn,:] = ndisp\n", "        desmat[idxu,:] = udisp\n", "        dmrows[idxe] = (sname + 'E')\n", "        dmrows[idxn] = (sname + 'N')\n", "        dmrows[idxu] = (sname + 'U')\n", "        sclat[idxe] = slat\n", "        sclat[idxn] = slat\n", "        sclat[idxu] = slat\n", "        sclon[idxe] = slon\n", "        sclon[idxn] = slon\n", "        sclon[idxu] = slon"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Write Design Matrix to File"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["if (rank == 0):\n", "    print(\":: Writing netCDF-formatted file.\")\n", "    f_out = (\"designmatrix_\" + rfm + \"_\" + outstr + \".nc\")\n", "    f_file = (\"../output/DesignMatrixLoad/\" + f_out)\n", "    # Open new NetCDF file in \"write\" mode\n", "    dataset = netCDF4.Dataset(f_file,'w',format='NETCDF4_CLASSIC')\n", "    # Define dimensions for variables\n", "    desmat_shape = desmat.shape\n", "    num_rows = desmat_shape[0]\n", "    num_cols = desmat_shape[1]\n", "    nstacomp = dataset.createDimension('nstacomp',num_rows)\n", "    nloadcell = dataset.createDimension('nloadcell',num_cols)\n", "    nchars = dataset.createDimension('nchars',10)\n", "    # Create variables\n", "    sta_comp_id = dataset.createVariable('sta_comp_id','S1',('nstacomp','nchars'))\n", "    load_cell_id = dataset.createVariable('load_cell_id','S1',('nloadcell','nchars'))\n", "    design_matrix = dataset.createVariable('design_matrix',float,('nstacomp','nloadcell'))\n", "    sta_comp_lat = dataset.createVariable('sta_comp_lat',float,('nstacomp',))\n", "    sta_comp_lon = dataset.createVariable('sta_comp_lon',float,('nstacomp',))\n", "    load_cell_lat = dataset.createVariable('load_cell_lat',float,('nloadcell',))\n", "    load_cell_lon = dataset.createVariable('load_cell_lon',float,('nloadcell',))\n", "    # Add units\n", "    sta_comp_id.units = 'string'\n", "    sta_comp_id.long_name = 'station_component_id'\n", "    load_cell_id.units = 'string'\n", "    load_cell_id.long_name = 'load_cell_id'\n", "    design_matrix.units = 'mm'\n", "    design_matrix.long_name = 'displacement_mm'\n", "    sta_comp_lat.units = 'degrees_north'\n", "    sta_comp_lat.long_name = 'station_latitude'\n", "    sta_comp_lon.units = 'degrees_east'\n", "    sta_comp_lon.long_name = 'station_longitude'\n", "    load_cell_lat.units = 'degrees_north'\n", "    load_cell_lat.long_name = 'loadcell_latitude'\n", "    load_cell_lon.units = 'degrees_east'\n", "    load_cell_lon.long_name = 'loadcell_longitude'\n", "    # Assign data\n", "    #  https://unidata.github.io/netcdf4-python/ (see \"Dealing with Strings\")\n", "    #  sta_comp_id[:] = netCDF4.stringtochar(np.array(dmrows,dtype='S10'))\n", "    #  load_cell_id[:] = netCDF4.stringtochar(np.array(load_cells,dtype='S10'))\n", "    sta_comp_id._Encoding = 'ascii'\n", "    sta_comp_id[:] = np.array(dmrows,dtype='S10')\n", "    load_cell_id._Encoding = 'ascii'\n", "    load_cell_id[:] = np.array(load_cells,dtype='S10')\n", "    design_matrix[:,:] = desmat\n", "    sta_comp_lat[:] = sclat\n", "    sta_comp_lon[:] = sclon\n", "    load_cell_lat[:] = lclat\n", "    load_cell_lon[:] = lclon\n", "    # Write Data to File\n", "    dataset.close()\n\n", "    # Read the netCDF file as a test\n", "    f = netCDF4.Dataset(f_file)\n", "    #print(f.variables)\n", "    sta_comp_ids = f.variables['sta_comp_id'][:]\n", "    load_cell_ids = f.variables['load_cell_id'][:]\n", "    design_matrix = f.variables['design_matrix'][:]\n", "    sta_comp_lat = f.variables['sta_comp_lat'][:]\n", "    sta_comp_lon = f.variables['sta_comp_lon'][:]\n", "    load_cell_lat = f.variables['load_cell_lat'][:]\n", "    load_cell_lon = f.variables['load_cell_lon'][:]\n", "    f.close()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["--------------------- END CODE --------------------------- #"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.6.4"}}, "nbformat": 4, "nbformat_minor": 2}