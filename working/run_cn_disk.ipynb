{"cells": [{"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["#!/usr/bin/env python"]}, {"cell_type": "markdown", "metadata": {}, "source": ["*********************************************************************<br>\n", "MAIN PROGRAM TO PREDICT SURFACE DISPLACEMENTS CAUSED BY SURFACE MASS LOADING <br>\n", "BY CONVOLVING DISPLACEMENT LOAD GREENS FUNCTIONS WITH A MODEL FOR A SURFACE MASS LOAD <br>\n", "<br>\n", "Copyright (c) 2014-2019: HILARY R. MARTENS, LUIS RIVERA, MARK SIMONS         <br>\n", "<br>\n", "This file is part of LoadDef.<br>\n", "<br>\n", "   LoadDef is free software: you can redistribute it and/or modify<br>\n", "   it under the terms of the GNU General Public License as published by<br>\n", "   the Free Software Foundation, either version 3 of the License, or<br>\n", "   any later version.<br>\n", "<br>\n", "   LoadDef is distributed in the hope that it will be useful,<br>\n", "   but WITHOUT ANY WARRANTY; without even the implied warranty of<br>\n", "   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the<br>\n", "   GNU General Public License for more details.<br>\n", "<br>\n", "   You should have received a copy of the GNU General Public License<br>\n", "   along with LoadDef.  If not, see <https://www.gnu.org/licenses/>.<br>\n", "<br>\n", "*********************************************************************"]}, {"cell_type": "markdown", "metadata": {}, "source": ["IMPORT PRINT FUNCTION"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from __future__ import print_function"]}, {"cell_type": "markdown", "metadata": {}, "source": ["IMPORT MPI MODULE"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from mpi4py import MPI"]}, {"cell_type": "markdown", "metadata": {}, "source": ["MODIFY PYTHON PATH TO INCLUDE 'LoadDef' DIRECTORY"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import sys\n", "import os\n", "sys.path.append(os.getcwd() + \"/../\")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["IMPORT PYTHON MODULES"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import numpy as np\n", "import scipy as sc\n", "import datetime\n", "from CONVGF.CN import load_convolution\n", "from CONVGF.utility import read_station_file"]}, {"cell_type": "markdown", "metadata": {}, "source": ["--------------- SPECIFY USER INPUTS --------------------- #"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Reference Frame (used for filenames) [Blewitt 2003]"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["rfm = \"ce\""]}, {"cell_type": "markdown", "metadata": {}, "source": ["Greens Function File<br>\n", " :: May be load Green's function file output directly from run_gf.py (norm_flag = False)<br>\n", " :: May be from a published table, normalized according to Farrell (1972) conventions [theta, u_norm, v_norm]"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["pmodel = (\"PREM\")\n", "grn_file = (\"../output/Greens_Functions/\" + rfm + \"_\" + pmodel + \".txt\")\n", "norm_flag  = False\n", " \n", "# Full Path to Load Directory and Prefix of Filename\n", "loadfile_directory = (\"../output/Grid_Files/nc/Custom/\")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Prefix for the Load Files (Load Directory will be Searched for all Files Starting with this Prefix)<br>\n", " :: Note: For Load Files Organized by Date, the End of Filename Name Must be in the Format yyyymmddhhmnsc.txt<br>\n", " :: Note: If not organized by date, files may be organized by tidal harmonic, for example (i.e. a unique filename ending)<br>\n", " :: Note: Output names (within output files) will be determined by extension following last underscore character (e.g., date/harmonic/model)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["loadfile_prefix = (\"convgf_disk_1m\")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["LoadFile Format: [\"nc\", \"txt\"]"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["loadfile_format = \"nc\"\n", " \n", "# Are the Load Files Organized by Datetime?\n", "#  :: If False, all Files that match the loadfile directory and prefix will be analyzed.\n", "time_series = False "]}, {"cell_type": "markdown", "metadata": {}, "source": ["Date Range for Computation (Year,Month,Day,Hour,Minute,Second)<br>\n", " :: Note: Only used if 'time_series' is True"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["frst_date = [2015,1,1,0,0,0]\n", "last_date = [2016,3,1,0,0,0]"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Are the load values on regular grids (speeds up interpolation); If unsure, leave as false."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["regular = True"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Load Density<br>\n", " Recommended: 1025-1035 for oceanic loads (e.g., FES2014, ECCO2); 1 for atmospheric loads (e.g. ECMWF)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["ldens = 1000.0\n", "  \n", "# Ocean/Land Mask \n", "#  :: 0 = do not mask ocean or land (retain full model); 1 = mask out land (retain ocean); 2 = mask out oceans (retain land)\n", "#  :: Recommended: 1 for oceanic; 2 for atmospheric\n", "lsmask_type = 0"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Full Path to Land-Sea Mask File (May be Irregular and Sparse)<br>\n", " :: Format: Lat, Lon, Mask [0=ocean; 1=land]"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["lsmask_file = (\"../input/Land_Sea/ETOPO1_Ice_g_gmt4_wADD.txt\")\n", " \n", "# Station/Grid-Point Location File (Lat, Lon, StationName)\n", "sta_file = (\"../input/Station_Locations/Lat_Profile_Select.txt\")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["-- Mesh Paramters -- High Resolution<br>\n", "el1 = 0.001    # increment in angular resolution (degrees) for innermost zone<br>\n", "el2 = 0.005    # increment in angular resolution for second zone<br>\n", "el3 = 0.01     # increment in angular resolution for third zone<br>\n", "el4 = 0.1      # increment in angular resolution for fourth zone<br>\n", "el5 = 0.5      # increment in angular resolution for fifth zone<br>\n", "el6 = 1.0      # increment in angular resolution for outermost zone<br>\n", "1 = 11.0       # outer edge of innermost zone (degrees)<br>\n", "2 = 15.0       # outer edge of second zone<br>\n", "3 = 20.0       # outer edge of third zone<br>\n", "4 = 30.0       # outer edge of fourth zone<br>\n", "5 = 90.0       # outer edge of fifth zone<br>\n", "zm = 0.5       # increment in azimuthal resolution (degrees)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": [" \n", "# -- Mesh Paramters -- Lower Resolution (faster)\n", "del1 = 0.001    # increment in angular resolution (degrees) for innermost zone\n", "del2 = 0.01     # increment in angular resolution for second zone\n", "del3 = 0.1      # increment in angular resolution for third zone\n", "del4 = 0.2      # increment in angular resolution for fourth zone\n", "del5 = 0.5      # increment in angular resolution for fifth zone\n", "del6 = 1.0      # increment in angular resolution for outermost zone\n", "z1 = 0.6        # outer edge of innermost zone (degrees)\n", "z2 = 1.0        # outer edge of second zone\n", "z3 = 2.0        # outer edge of third zone\n", "z4 = 5.0        # outer edge of fourth zone\n", "z5 = 10.0       # outer edge of fifth zone\n", "azm = 1.0       # increment in azimuthal resolution (degrees)\n", " \n", "# Optional: Additional string to include in output filenames (e.g. \"_2019\")\n", "outstr = (\"_\" + pmodel)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["------------------ END USER INPUTS ----------------------- #"]}, {"cell_type": "markdown", "metadata": {}, "source": ["-------------------- SETUP MPI --------------------------- #"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Get the Main MPI Communicator That Controls Communication Between Processors"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["comm = MPI.COMM_WORLD\n", "# Get My \"Rank\", i.e. the Processor Number Assigned to Me\n", "rank = comm.Get_rank()\n", "# Get the Total Number of Other Processors Used\n", "size = comm.Get_size()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["---------------------------------------------------------- #"]}, {"cell_type": "markdown", "metadata": {}, "source": ["-------------------- BEGIN CODE -------------------------- #"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Ensure that the Output Directories Exist"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["if (rank == 0):\n", "    if not (os.path.isdir(\"../output/Convolution/\")):\n", "        os.makedirs(\"../output/Convolution/\")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Check format of load files"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["if not (loadfile_format == \"nc\"):\n", "    if not (loadfile_format == \"txt\"):\n", "        print(\":: Error: Invalid format for load files. See scripts in the /GRDGEN/load_files/ folder. Acceptable formats: netCDF, txt.\")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Read in the Land-Sea Mask"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["if (lsmask_type > 0):\n", "    lslat,lslon,lsmask = read_lsmask.main(lsmask_file)\n", "else:\n", "    # Doesn't really matter so long as there are some values filled in with something other than 1 or 2\n", "    lat1d = np.arange(-90.,90.,2.)\n", "    lon1d = np.arange(0.,360.,2.)\n", "    olon,olat = np.meshgrid(lon1d,lat1d)\n", "    lslat = olat.flatten()\n", "    lslon = olon.flatten()\n", "    lsmask = np.ones((len(lslat),)) * -1.\n", "print(':: Finished Reading in LSMask.')"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Ensure that Land-Sea Mask Longitudes are in Range 0-360"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["neglon_idx = np.where(lslon<0.)\n", " \n", "# Read Station & Date Range File\n", "lat,lon,sta = read_station_file.main(sta_file)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Determine Number of Stations Read In"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["if isinstance(lat,float) == True: # only 1 station\n", "    numel = 1\n", "else:\n", "    numel = len(lat)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Loop Through Each Station"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["for jj in range(0,numel):\n\n", "    # Remove Index If Only 1 Station\n", "    if (numel == 1): # only 1 station read in\n", "        my_sta = sta\n", "        my_lat = lat\n", "        my_lon = lon\n", "    else:\n", "        my_sta = sta[jj]\n", "        my_lat = lat[jj]\n", "        my_lon = lon[jj]\n\n", "    # Decode station name if necessary\n", "    try: \n", "        my_sta = my_sta.decode()\n", "    except: \n", "        print(':: No need to decode station.')\n\n", "    # If Rank is Main, Output Station Name\n", "    if (rank == 0):\n", "        print(' ')\n", "        print(':: Starting on Station: ' + my_sta)\n\n", "    # Output File Name\n", "    cnv_out = my_sta + \"_\" + rfm + \"_\" + loadfile_prefix + outstr + \".txt\"\n\n", "    # Convert Start and End Dates to Datetimes\n", "    if (time_series == True):\n", "        frstdt = datetime.datetime(frst_date[0],frst_date[1],frst_date[2],frst_date[3],frst_date[4],frst_date[5])\n", "        lastdt = datetime.datetime(last_date[0],last_date[1],last_date[2],last_date[3],last_date[4],last_date[5])\n\n", "    # Determine Number of Matching Load Files\n", "    load_files = []\n", "    if os.path.isdir(loadfile_directory):\n", "        for mfile in os.listdir(loadfile_directory): # Filter by Load Directory\n", "            if mfile.startswith(loadfile_prefix): # Filter by File Prefix\n", "                if (time_series == True):\n", "                    if (loadfile_format == \"txt\"):\n", "                        mydt = datetime.datetime.strptime(mfile[-18:-4],'%Y%m%d%H%M%S') # Convert Filename String to Datetime\n", "                    elif (loadfile_format == \"nc\"):\n", "                        mydt = datetime.datetime.strptime(mfile[-17:-3],'%Y%m%d%H%M%S') # Convert Filename String to Datetime\n", "                    else:\n", "                        print(\":: Error: Invalid format for load files. See scripts in the /GRDGEN/load_files/ folder. Acceptable formats: netCDF, txt.\")\n", "                    if ((mydt >= frstdt) & (mydt <= lastdt)): # Filter by Date Range\n", "                        load_files.append(loadfile_directory + mfile) # Append File to List\n", "                else:\n", "                    load_files.append(loadfile_directory + mfile) # Append File to List\n", "    else:\n", "        sys.exit('Error: The loadfile directory does not exist. You may need to create it. The /GRDGEN/load_files/ folder contains utility scripts to convert common models into LoadDef-compatible formats, and will automatically create a loadfile directory.')\n\n", "    # Test for Load Files\n", "    if not load_files:\n", "        sys.exit('Error: Could not find load files. You may need to generate them. The /GRDGEN/load_files/ folder contains utility scripts to convert common models into LoadDef-compatible formats.')\n\n", "    # Sort the Filenames\n", "    load_files = np.asarray(load_files)\n", "    fidx = np.argsort(load_files)\n", "    load_files = load_files[fidx]\n\n", "    # Set Lat/Lon/Name for Current Station\n", "    slat = my_lat\n", "    slon = my_lon\n", "    sname = my_sta\n\n", "    # Determine the Chunk Sizes for the Convolution\n", "    total_files = len(load_files)\n", "    nominal_load = total_files // size # Floor Divide\n", "    # Final Chunk Might Be Different in Size Than the Nominal Load\n", "    if rank == size - 1:\n", "        procN = total_files - rank * nominal_load\n", "    else:\n", "        procN = nominal_load\n\n", "    # Perform the Convolution for Each Station\n", "    if (rank == 0):\n", "        eamp,epha,namp,npha,vamp,vpha = load_convolution.main(grn_file,norm_flag,load_files,regular,\\\n", "            lslat,lslon,lsmask,slat,slon,sname,cnv_out,lsmask_type,loadfile_format,rank,procN,comm,load_density=ldens,\\\n", "            delinc1=del1,delinc2=del2,delinc3=del3,delinc4=del4,delinc5=del5,delinc6=del6,izb=z1,z2b=z2,z3b=z3,z4b=z4,z5b=z5,azminc=azm)\n", "            #izb=1.1,z2b=2.0,z3b=5.0,azminc=0.5)\n", "            #,izb=0.002,delinc1=0.00005,z2b=0.02,delinc2=0.0001,z3b=0.1,delinc3=0.001)\n", "    # For Worker Ranks, Run the Code But Don't Return Any Variables\n", "    else:\n", "        load_convolution.main(grn_file,norm_flag,load_files,regular,\\\n", "            lslat,lslon,lsmask,slat,slon,sname,cnv_out,lsmask_type,loadfile_format,rank,procN,comm,load_density=ldens,\\\n", "            delinc1=del1,delinc2=del2,delinc3=del3,delinc4=del4,delinc5=del5,delinc6=del6,izb=z1,z2b=z2,z3b=z3,z4b=z4,z5b=z5,azminc=azm)\n", "            #izb=1.1,z2b=2.0,z3b=5.0,azminc=0.5) \n", "            #,izb=0.002,delinc1=0.00005,z2b=0.02,delinc2=0.0001,z3b=0.1,delinc3=0.001)\n\n", "    # Make Sure All Jobs Have Finished Before Continuing\n", "    comm.Barrier()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["--------------------- END CODE --------------------------- #"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.6.4"}}, "nbformat": 4, "nbformat_minor": 2}